{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Wing Wing","title":"Home"},{"location":"#wing","text":"Wing","title":"Wing"},{"location":"p1/overview/","text":"LSM Basic The code is in src/storage/lsm . The architecture of the LSM-tree in Wing is as follows. DBImpl : At the highest level, the DBImpl is the primary component responsible for interacting with users. It references the most recent SuperVersion of the database. It is in lsm.hpp . SuperVersion : It includes a MemTable, a list of immutable MemTables and the on-disk LSM-tree Version , which together represent the current state of the database. It is in version.hpp . MemTable : An in-memory ordered data structure. It is flushed to disk when it reaches its capacity. It is in memtable.hpp . Version : An array of levels, representing the on-disk LSM-tree. It is in version.hpp . Level : It is composed of one or more sorted runs. It is in level.hpp . SortedRun : It can be viewed as a sorted key-value array which is divided into several SSTables. It is in level.hpp . SSTable : It is composed of data blocks, an index, bloom filter and metadata. It is in sst.hpp . Block : It stores records. It is in block.hpp . Record Format Records in the database are structured as (key, seq, type, value) tuple, where seq denotes the timestamp (or sequence number) and type denotes the record type. A record with type=RecordType::Value represents the key-value pair at the timestamp seq . When type equals to RecordType::Deletion , the record indicates that the key has been marked for deletion at the timestamp seq . (key, seq, type) is called the internal key of record (see storage/lsm/format.hpp ) because seq and type are invisible to users. We can define a comparing function to sort them: for two internal keys (key0, seq0, type0) and (key1, seq1, type1) , the former is smaller than the latter if and only if key0 < key1 or key0 == key1 && seq0 > seq1 . With this comparing function, for (key, seq) , the newest record with the same key and a sequence number seq0 <= seq is the first record (key0, seq0) with (key, seq) <= (key0, seq0) . Get DBImpl::Get(key, seq, &value_str) function is designed to retrieve records from the database. It looks for the first record (key0, seq0, type0) satisfying key0 == key && seq0 <= seq . If the record is a record with type RecordType::Deletion or no such record exists, the function returns false, indicating the requested value is not found. If a record with type RecordType::Value is found, the function returns true and copies the associated value into value_str . The process of Get is: Check if MemTable has the record. If not, check if immutable MemTables have the record. It checks from the newest immutable MemTable to the oldest immutable MemTable. It stops once it finds the record. If they do not have the record, proceed to check the on-disk LSM-tree. Check if Level 0 has the record, then Level 1, 2, and so on. For each level, it performs a binary search to find the SSTable that possibly has the record. Then it queries the bloom filter. If further inquiry is necessary, it performs a binary search on the SSTable's index to find the data block. It reads the data block from the disk, and performs a binary search to find the record. Put and Delete DBImpl::Put(key, seq) creates a new record (key, seq, RecordType::Value, value) and DBImpl::Del(key, seq) creates a new record (key, seq, RecordType::Deletion) . Once a record is created, it is inserted to the MemTable. For convenience, a lock is employed to ensure that only a single writer can perform operations at any given time. If the MemTable reaches its capacity, it creates a new superversion and moves the MemTable to the immutable MemTable list and create a new MemTable. The database has 2 threads to persist the data to disk: the flush thread and the compaction thread. The flush thread is awakened whenever a new immutable MemTable is created. It flushes the immutable MemTables to the first level (Level 0) of the LSM-tree. Every time an immutable Memtable is flushed, the compaction thread is awakened. It acquires new compaction tasks through CompactionPicker::Get . Once it has tasks, it proceeds to execute them and subsequently updates the superversion. Scan The database supports range scans. DBImpl::Begin() returns an iterator positioned to the beginning of the data, while DBImpl::Seek(key, seq) returns an iterator positioned to the first record (key0, seq0, type0) satisfying (key, seq) <= (key0, seq0) . Scan operations are performed in a snapshot. When a DBIterator is created, it stores the current sequence number. It can only see the records with sequence number smaller than the stored sequence number. The architecture of iterators is as follows. BlockIterator is the iterator on data blocks. SSTableIterator is the iterator on SSTables and contains a BlockIterator . SortedRunIterator is the iterator on sorted runs and contains a SSTableIterator . SuperVersionIterator is the iterator on superversions, it contains all the SortedRunIterator s and MemTableIterator s using IteratorHeap , which maintains the record with the minimum internal key by maintaining iterators in a heap. There is no LevelIterator or VersionIterator because it is inefficient to maintain two IteratorHeap s. The DBIterator operates at the highest level, merging records with the same key and skipping the keys which are marked deleted. The interfaces of Iterator can be found in storage/lsm/iterator.hpp . Here is an example of usage: DBIterator it = ...; // create the iterator while (it.Valid()) { // Read key and value of the current entry auto key = it.key(); auto value = it.value(); // output key and value DB_INFO(\"{}, {}\", key, value); // Move to the next entry it.Next(); // After moving, key and value may be invalid because they are `Slice`s, // i.e. references to a internal buffer in `it`. }","title":"Overview"},{"location":"p1/overview/#lsm-basic","text":"The code is in src/storage/lsm . The architecture of the LSM-tree in Wing is as follows. DBImpl : At the highest level, the DBImpl is the primary component responsible for interacting with users. It references the most recent SuperVersion of the database. It is in lsm.hpp . SuperVersion : It includes a MemTable, a list of immutable MemTables and the on-disk LSM-tree Version , which together represent the current state of the database. It is in version.hpp . MemTable : An in-memory ordered data structure. It is flushed to disk when it reaches its capacity. It is in memtable.hpp . Version : An array of levels, representing the on-disk LSM-tree. It is in version.hpp . Level : It is composed of one or more sorted runs. It is in level.hpp . SortedRun : It can be viewed as a sorted key-value array which is divided into several SSTables. It is in level.hpp . SSTable : It is composed of data blocks, an index, bloom filter and metadata. It is in sst.hpp . Block : It stores records. It is in block.hpp .","title":"LSM Basic"},{"location":"p1/overview/#record-format","text":"Records in the database are structured as (key, seq, type, value) tuple, where seq denotes the timestamp (or sequence number) and type denotes the record type. A record with type=RecordType::Value represents the key-value pair at the timestamp seq . When type equals to RecordType::Deletion , the record indicates that the key has been marked for deletion at the timestamp seq . (key, seq, type) is called the internal key of record (see storage/lsm/format.hpp ) because seq and type are invisible to users. We can define a comparing function to sort them: for two internal keys (key0, seq0, type0) and (key1, seq1, type1) , the former is smaller than the latter if and only if key0 < key1 or key0 == key1 && seq0 > seq1 . With this comparing function, for (key, seq) , the newest record with the same key and a sequence number seq0 <= seq is the first record (key0, seq0) with (key, seq) <= (key0, seq0) .","title":"Record Format"},{"location":"p1/overview/#get","text":"DBImpl::Get(key, seq, &value_str) function is designed to retrieve records from the database. It looks for the first record (key0, seq0, type0) satisfying key0 == key && seq0 <= seq . If the record is a record with type RecordType::Deletion or no such record exists, the function returns false, indicating the requested value is not found. If a record with type RecordType::Value is found, the function returns true and copies the associated value into value_str . The process of Get is: Check if MemTable has the record. If not, check if immutable MemTables have the record. It checks from the newest immutable MemTable to the oldest immutable MemTable. It stops once it finds the record. If they do not have the record, proceed to check the on-disk LSM-tree. Check if Level 0 has the record, then Level 1, 2, and so on. For each level, it performs a binary search to find the SSTable that possibly has the record. Then it queries the bloom filter. If further inquiry is necessary, it performs a binary search on the SSTable's index to find the data block. It reads the data block from the disk, and performs a binary search to find the record.","title":"Get"},{"location":"p1/overview/#put-and-delete","text":"DBImpl::Put(key, seq) creates a new record (key, seq, RecordType::Value, value) and DBImpl::Del(key, seq) creates a new record (key, seq, RecordType::Deletion) . Once a record is created, it is inserted to the MemTable. For convenience, a lock is employed to ensure that only a single writer can perform operations at any given time. If the MemTable reaches its capacity, it creates a new superversion and moves the MemTable to the immutable MemTable list and create a new MemTable. The database has 2 threads to persist the data to disk: the flush thread and the compaction thread. The flush thread is awakened whenever a new immutable MemTable is created. It flushes the immutable MemTables to the first level (Level 0) of the LSM-tree. Every time an immutable Memtable is flushed, the compaction thread is awakened. It acquires new compaction tasks through CompactionPicker::Get . Once it has tasks, it proceeds to execute them and subsequently updates the superversion.","title":"Put and Delete"},{"location":"p1/overview/#scan","text":"The database supports range scans. DBImpl::Begin() returns an iterator positioned to the beginning of the data, while DBImpl::Seek(key, seq) returns an iterator positioned to the first record (key0, seq0, type0) satisfying (key, seq) <= (key0, seq0) . Scan operations are performed in a snapshot. When a DBIterator is created, it stores the current sequence number. It can only see the records with sequence number smaller than the stored sequence number. The architecture of iterators is as follows. BlockIterator is the iterator on data blocks. SSTableIterator is the iterator on SSTables and contains a BlockIterator . SortedRunIterator is the iterator on sorted runs and contains a SSTableIterator . SuperVersionIterator is the iterator on superversions, it contains all the SortedRunIterator s and MemTableIterator s using IteratorHeap , which maintains the record with the minimum internal key by maintaining iterators in a heap. There is no LevelIterator or VersionIterator because it is inefficient to maintain two IteratorHeap s. The DBIterator operates at the highest level, merging records with the same key and skipping the keys which are marked deleted. The interfaces of Iterator can be found in storage/lsm/iterator.hpp . Here is an example of usage: DBIterator it = ...; // create the iterator while (it.Valid()) { // Read key and value of the current entry auto key = it.key(); auto value = it.value(); // output key and value DB_INFO(\"{}, {}\", key, value); // Move to the next entry it.Next(); // After moving, key and value may be invalid because they are `Slice`s, // i.e. references to a internal buffer in `it`. }","title":"Scan"},{"location":"p1/part1/","text":"Part 1 In part 1, you will implement BlockIterator , BlockBuilder , SSTable , SSTableIterator and SSTableBuilder . SortedRun , SortedRunIterator . IteratorHeap . SuperVersion , SuperVersionIterator and Version . Each class contains some incomplete methods. You may add fields and methods as needed, but do not remove any existing fields or remove public methods, nor change the names of the methods. Block Block stores internal keys and values. If you do not have time to design complex formats such as a compressed format, we highly recommend you to implement the simplest format as follows: where the block is divided into two parts, the first part consists of key-value pairs, while the second part is an array of offsets to the key-value pairs. BlockIterator takes a pointer to the beginning of the Block (which is stored in a buffer) and the BlockHandle of the Block . You can obtain useful information such as the number of key-value pairs and the size of the Block in BlockHandle . BlockIterator::Seek(user_key, seq) finds the first record larger than (user_key, seq) and moves to it (refer to the definition of the comparison operator in storage/lsm/format.hpp ). BlockIterator::SeekToFirst moves the iterator to the beginning. You can find the comments for Next() , key() , value() and Valid() in storage/lsm/iterator.hpp . BlockBuilder writes key-value pairs to the block until the block reaches the capacity (refer to block_size in storage/lsm/options.hpp , this parameter is passed in the constructor of BlockBuilder ). BlockBuilder::Append returns false if the block is full. You need to ensure that the size of the block do not exceed block_size . The offsets of key-value pairs are written after all the key-value pairs are written and BlockBuilder::FinishBlock is called, so you need to record the offsets while writing the data. The code is in block.hpp and block.cpp . Slice Note that `Slice is equivalent to std::string_view (C++17), which is a reference to a string. It does not allocate a std::string . You need to ensure that the referenced string is not incorrectly deallocated or modified. Test You can test it through test/test_lsm --gtest_filter=LSMTest.BlockTest SSTable You can implement the format as follows: where data blocks are Block . The index consists of the last key and the BlockHandle of each Block , as defined in IndexValue in storage/lsm/format.hpp . It is utilized to locate data block in SSTable::Get , SSTable::Seek and SSTableIterator::Seek . It is preloaded to the memory when opening the SSTable. The bloom filter is used to test whether a key may exist in the SSTable during SSTable::Get . It is also preloaded to the memory. You will implement SSTableBuilder::Append and SSTableBuilder::Finish while maintaining the information about the SSTable: index_data_ (the index data), index_offset_ (the offset of the index block), bloom_filter_offset_ (the offset of the bloom filter), largest_key_ and smallest_key_ (which represent the key range of the SSTable), key_hashes_ . Once a SSTable is created, the information of the SSTable is transferred to the SSTable structure. You can use BlockBuilder to build data blocks. After writing all the key-value pairs, you can write the index data and the metadata to the file. Since we assume that we preload the index data when we open the SSTable, there is no need to use Block to store index data. The code is in sst.cpp and sst.hpp . FileWriter You should use FileWriter to implement SSTableBuilder , BlockBuilder . It collects data and writes them to disk in batch. FileWriter provides two methods WriteValue<T> and WriteString . You can use WriteValue<T> to copy a value of type T to the file. T is a template parameter, it can be uint64_t , float , or structured data which do not have pointers, such as std::pair<uint64_t, uint64_t> and BlockHandle . For string data, you can use WriteString . It only writes the string data, for example, if the string is abc , then it writes 3 bytes a , b and c . Here is an example of usage: std::string str(\"114514\"); writer.WriteValue<uint64_t>(str.length()); .WriteString(str); Note that you should call FileWriter::Flush when all things have been written. If you think the methods of FileWriter is difficult to use, you can modify them, but DO NOT read/write to a raw file handle in SSTableBuilder ! FileReader You can use FileReader to read metadata and index data while initializing SSTable . The method ReadValue and ReadString is similar to WriteValue and WriteString . Here is an example of usage: // Read the string \"114514\" reader.Seek(offset); auto len = reader.ReadValue<uint64_t>(); auto str = reader.ReadString(len); Bloom filter You will build a bloom filter for each SSTable. If you are not familiar with bloom filter, you can read about it in resources such as link . Basically, bloom filter is a bit array. For each key, it set some bits to 1. The positions of these bits are calculated using hash functions. Then, for each key, if all the corresponding bits are 1, the key may exist, otherwise it does not. We have implemented a bloom filter for you, which can be found in common/bloomfilter.hpp and common/bloomfilter.cpp . BloomFilter::Create create a bloom filter. BloomFilter::Add add a key to the bloom filter. Since we only use the hash of keys, you can pass the hash to BloomFilter::Add . BloomFilter::Find checks if a key may exist in the bloom filter. It can also accept the hash of keys. In SSTableBuilder , you should record the hashes of keys in SSTableBuilder::Append and use them to build a bloom filter in SSTableBuilder::Finish . Test You can test it through test/test_lsm --gtest_filter=LSMTest.SSTableTest SortedRun SortedRun stores an array of SSTables. You will implement it based on SSTable and SSTableIterator . The code is in level.cpp and level.hpp . Test You can test it through test/test_lsm --gtest_filter=LSMTest.SortedRunTest IteratorHeap The IteratorHeap structure is used when performing merge-sort on multiple sorted runs. IteratorHeap takes references to the iterators, so you need to store the iterator in another area and pass the reference to it. The usage of IteratorHeap is as follows: First, call IteratorHeap::Push to pass references to the iterators to it. Then, if it is necessary, call IteratorHeap::Build to do some preprocessing. Then, you can use Next , key , value , Valid as an ordinary iterator. It returns the minimum record each time and call Next on the corresponding iterator. We recommend you to use a heap to maintain the minimum record. You can use std::priority_queue or implement your own. The code is in iterator_heap.hpp . Note that IteratorHeap is a template class, if you are not familiar with it, you can read about templates in resources such as link . Test You can test it through test/test_lsm --gtest_filter=LSMTest.IteratorHeapTest SuperVersion After you implement SortedRun , SortedRunIterator and IteratorHeap , implementing SuperVersion should be straightforward. The code is in version.cpp and version.hpp . Test You can test it through test/test_lsm --gtest_filter=LSMTest.SuperVersionTest Smart Pointers We use smart pointers to manage reference counts for SSTables and sorted runs. If you are not familiar with them, you can read about smart pointers in resources such as link . DO NOT delete them! We rely on reference counts to support multiversion concurrency control. Submit make submit in the build directory to create submission.zip and submit it to autolab.","title":"Part 1"},{"location":"p1/part1/#part-1","text":"In part 1, you will implement BlockIterator , BlockBuilder , SSTable , SSTableIterator and SSTableBuilder . SortedRun , SortedRunIterator . IteratorHeap . SuperVersion , SuperVersionIterator and Version . Each class contains some incomplete methods. You may add fields and methods as needed, but do not remove any existing fields or remove public methods, nor change the names of the methods.","title":"Part 1"},{"location":"p1/part1/#block","text":"Block stores internal keys and values. If you do not have time to design complex formats such as a compressed format, we highly recommend you to implement the simplest format as follows: where the block is divided into two parts, the first part consists of key-value pairs, while the second part is an array of offsets to the key-value pairs. BlockIterator takes a pointer to the beginning of the Block (which is stored in a buffer) and the BlockHandle of the Block . You can obtain useful information such as the number of key-value pairs and the size of the Block in BlockHandle . BlockIterator::Seek(user_key, seq) finds the first record larger than (user_key, seq) and moves to it (refer to the definition of the comparison operator in storage/lsm/format.hpp ). BlockIterator::SeekToFirst moves the iterator to the beginning. You can find the comments for Next() , key() , value() and Valid() in storage/lsm/iterator.hpp . BlockBuilder writes key-value pairs to the block until the block reaches the capacity (refer to block_size in storage/lsm/options.hpp , this parameter is passed in the constructor of BlockBuilder ). BlockBuilder::Append returns false if the block is full. You need to ensure that the size of the block do not exceed block_size . The offsets of key-value pairs are written after all the key-value pairs are written and BlockBuilder::FinishBlock is called, so you need to record the offsets while writing the data. The code is in block.hpp and block.cpp .","title":"Block"},{"location":"p1/part1/#slice","text":"Note that `Slice is equivalent to std::string_view (C++17), which is a reference to a string. It does not allocate a std::string . You need to ensure that the referenced string is not incorrectly deallocated or modified.","title":"Slice"},{"location":"p1/part1/#test","text":"You can test it through test/test_lsm --gtest_filter=LSMTest.BlockTest","title":"Test"},{"location":"p1/part1/#sstable","text":"You can implement the format as follows: where data blocks are Block . The index consists of the last key and the BlockHandle of each Block , as defined in IndexValue in storage/lsm/format.hpp . It is utilized to locate data block in SSTable::Get , SSTable::Seek and SSTableIterator::Seek . It is preloaded to the memory when opening the SSTable. The bloom filter is used to test whether a key may exist in the SSTable during SSTable::Get . It is also preloaded to the memory. You will implement SSTableBuilder::Append and SSTableBuilder::Finish while maintaining the information about the SSTable: index_data_ (the index data), index_offset_ (the offset of the index block), bloom_filter_offset_ (the offset of the bloom filter), largest_key_ and smallest_key_ (which represent the key range of the SSTable), key_hashes_ . Once a SSTable is created, the information of the SSTable is transferred to the SSTable structure. You can use BlockBuilder to build data blocks. After writing all the key-value pairs, you can write the index data and the metadata to the file. Since we assume that we preload the index data when we open the SSTable, there is no need to use Block to store index data. The code is in sst.cpp and sst.hpp .","title":"SSTable"},{"location":"p1/part1/#filewriter","text":"You should use FileWriter to implement SSTableBuilder , BlockBuilder . It collects data and writes them to disk in batch. FileWriter provides two methods WriteValue<T> and WriteString . You can use WriteValue<T> to copy a value of type T to the file. T is a template parameter, it can be uint64_t , float , or structured data which do not have pointers, such as std::pair<uint64_t, uint64_t> and BlockHandle . For string data, you can use WriteString . It only writes the string data, for example, if the string is abc , then it writes 3 bytes a , b and c . Here is an example of usage: std::string str(\"114514\"); writer.WriteValue<uint64_t>(str.length()); .WriteString(str); Note that you should call FileWriter::Flush when all things have been written. If you think the methods of FileWriter is difficult to use, you can modify them, but DO NOT read/write to a raw file handle in SSTableBuilder !","title":"FileWriter"},{"location":"p1/part1/#filereader","text":"You can use FileReader to read metadata and index data while initializing SSTable . The method ReadValue and ReadString is similar to WriteValue and WriteString . Here is an example of usage: // Read the string \"114514\" reader.Seek(offset); auto len = reader.ReadValue<uint64_t>(); auto str = reader.ReadString(len);","title":"FileReader"},{"location":"p1/part1/#bloom-filter","text":"You will build a bloom filter for each SSTable. If you are not familiar with bloom filter, you can read about it in resources such as link . Basically, bloom filter is a bit array. For each key, it set some bits to 1. The positions of these bits are calculated using hash functions. Then, for each key, if all the corresponding bits are 1, the key may exist, otherwise it does not. We have implemented a bloom filter for you, which can be found in common/bloomfilter.hpp and common/bloomfilter.cpp . BloomFilter::Create create a bloom filter. BloomFilter::Add add a key to the bloom filter. Since we only use the hash of keys, you can pass the hash to BloomFilter::Add . BloomFilter::Find checks if a key may exist in the bloom filter. It can also accept the hash of keys. In SSTableBuilder , you should record the hashes of keys in SSTableBuilder::Append and use them to build a bloom filter in SSTableBuilder::Finish .","title":"Bloom filter"},{"location":"p1/part1/#test_1","text":"You can test it through test/test_lsm --gtest_filter=LSMTest.SSTableTest","title":"Test"},{"location":"p1/part1/#sortedrun","text":"SortedRun stores an array of SSTables. You will implement it based on SSTable and SSTableIterator . The code is in level.cpp and level.hpp .","title":"SortedRun"},{"location":"p1/part1/#test_2","text":"You can test it through test/test_lsm --gtest_filter=LSMTest.SortedRunTest","title":"Test"},{"location":"p1/part1/#iteratorheap","text":"The IteratorHeap structure is used when performing merge-sort on multiple sorted runs. IteratorHeap takes references to the iterators, so you need to store the iterator in another area and pass the reference to it. The usage of IteratorHeap is as follows: First, call IteratorHeap::Push to pass references to the iterators to it. Then, if it is necessary, call IteratorHeap::Build to do some preprocessing. Then, you can use Next , key , value , Valid as an ordinary iterator. It returns the minimum record each time and call Next on the corresponding iterator. We recommend you to use a heap to maintain the minimum record. You can use std::priority_queue or implement your own. The code is in iterator_heap.hpp . Note that IteratorHeap is a template class, if you are not familiar with it, you can read about templates in resources such as link .","title":"IteratorHeap"},{"location":"p1/part1/#test_3","text":"You can test it through test/test_lsm --gtest_filter=LSMTest.IteratorHeapTest","title":"Test"},{"location":"p1/part1/#superversion","text":"After you implement SortedRun , SortedRunIterator and IteratorHeap , implementing SuperVersion should be straightforward. The code is in version.cpp and version.hpp .","title":"SuperVersion"},{"location":"p1/part1/#test_4","text":"You can test it through test/test_lsm --gtest_filter=LSMTest.SuperVersionTest","title":"Test"},{"location":"p1/part1/#smart-pointers","text":"We use smart pointers to manage reference counts for SSTables and sorted runs. If you are not familiar with them, you can read about smart pointers in resources such as link . DO NOT delete them! We rely on reference counts to support multiversion concurrency control.","title":"Smart Pointers"},{"location":"p1/part1/#submit","text":"make submit in the build directory to create submission.zip and submit it to autolab.","title":"Submit"},{"location":"p1/part2/","text":"Part 2 In part 2, you will implement compaction mechanism. You will implement: LeveledCompactionPicker , which is derived from CompactionPicker . It generates a new compaction task. The parameters for the compaction task are stored in Compaction . It returns nullptr if no compaction is required for the LSM-tree. CompactionJob . This component receives an iterator and persists its output as a list of SSTables. It is utilized in both DBImpl::FlushThread and DBImpl::CompactionThread . DBImpl::CompactionThread . This thread manages the compaction process and updates the superversion. You may refer to the implementation of DBImpl::FlushThread for guidance. Leveled compaction strategy You will implement the leveled compaction strategy. This strategy is the default strategy of RocksDB. The leveled compaction strategy in Wing is as follows: Suppose the size ratio is T T , and the size limit of Level 0 is B B . The size limit of Level 1, 2, 3 \\cdots \\cdots is BT,BT^2,BT^3\\cdots BT,BT^2,BT^3\\cdots Level 0 consists of multiple sorted runs flushed by DBImpl::FlushThread , each sorted run has 1 or 2 SSTables. If the number of sorted runs is larger than 4, all the sorted runs are compacted to the next level. If the number of sorted runs reaches 20, then DBImpl::FlushThread stops to flush until they are compacted to the next level. Level 1, 2, 3 \\cdots \\cdots consists of only one sorted run. If one of them reaches its capacity, it picks an SSTable with the minimum overlapping with the next level, and compact the SSTable with the next level. In LeveledCompactionPicker::Get, you must check for the existence of a compaction task. If one exists, you must create and return a std::unique_ptr<Compaction> . Otherwise, return a nullptr. The code is in compaction_picker.hpp , compaction_picker.cpp , compaction.hpp . DBImpl::CompactionJob You will implement CompactionJob::Run. It receives an iterator and writes the iterator's output to disk. You should merge the records with the same key. The output is divided into SSTables, with the size of records in each SSTable not exceeding the target SSTable size (refer to sst_file_size in storage/lsm/options.hpp). The actual SSTable size may be larger than the target SSTable size since we have index data and metadata. The code is in compaction_job.hpp . DBImpl::CompactionThread The compaction thread awaits signals from the flush thread or the deconstructor via the condition variable compact_cv_. Upon being awakened, it first checks stop_signal_ . If stop_signal_ is true, it stops immediately. Otherwise, it calls CompactionPicker::Get to obtain a compaction task. If a task is present, it executes the compaction outside of the DB mutex. After compaction, it reacquires the DB mutex, creates a new superversion, and updates the DBImpl superversion. You can assume that the number of SSTables is small, allowing you to iterate through each SSTable and copy their pointers to the new superversion. The DB mutex should only be used for metadata operations. You must avoid performing the compaction process under the DB mutex. The code is in lsm.cpp and lsm.hpp . Remove old SSTables Utilize SetRemoveTag to set the remove_tag_ to true. When the destructor of SSTable is invoked, it checks the tag and determines whether to remove the file. This is safe as the destructor is called only when the SSTable is not in use. Test TODO","title":"Part 2"},{"location":"p1/part2/#part-2","text":"In part 2, you will implement compaction mechanism. You will implement: LeveledCompactionPicker , which is derived from CompactionPicker . It generates a new compaction task. The parameters for the compaction task are stored in Compaction . It returns nullptr if no compaction is required for the LSM-tree. CompactionJob . This component receives an iterator and persists its output as a list of SSTables. It is utilized in both DBImpl::FlushThread and DBImpl::CompactionThread . DBImpl::CompactionThread . This thread manages the compaction process and updates the superversion. You may refer to the implementation of DBImpl::FlushThread for guidance.","title":"Part 2"},{"location":"p1/part2/#leveled-compaction-strategy","text":"You will implement the leveled compaction strategy. This strategy is the default strategy of RocksDB. The leveled compaction strategy in Wing is as follows: Suppose the size ratio is T T , and the size limit of Level 0 is B B . The size limit of Level 1, 2, 3 \\cdots \\cdots is BT,BT^2,BT^3\\cdots BT,BT^2,BT^3\\cdots Level 0 consists of multiple sorted runs flushed by DBImpl::FlushThread , each sorted run has 1 or 2 SSTables. If the number of sorted runs is larger than 4, all the sorted runs are compacted to the next level. If the number of sorted runs reaches 20, then DBImpl::FlushThread stops to flush until they are compacted to the next level. Level 1, 2, 3 \\cdots \\cdots consists of only one sorted run. If one of them reaches its capacity, it picks an SSTable with the minimum overlapping with the next level, and compact the SSTable with the next level. In LeveledCompactionPicker::Get, you must check for the existence of a compaction task. If one exists, you must create and return a std::unique_ptr<Compaction> . Otherwise, return a nullptr. The code is in compaction_picker.hpp , compaction_picker.cpp , compaction.hpp .","title":"Leveled compaction strategy"},{"location":"p1/part2/#dbimplcompactionjob","text":"You will implement CompactionJob::Run. It receives an iterator and writes the iterator's output to disk. You should merge the records with the same key. The output is divided into SSTables, with the size of records in each SSTable not exceeding the target SSTable size (refer to sst_file_size in storage/lsm/options.hpp). The actual SSTable size may be larger than the target SSTable size since we have index data and metadata. The code is in compaction_job.hpp .","title":"DBImpl::CompactionJob"},{"location":"p1/part2/#dbimplcompactionthread","text":"The compaction thread awaits signals from the flush thread or the deconstructor via the condition variable compact_cv_. Upon being awakened, it first checks stop_signal_ . If stop_signal_ is true, it stops immediately. Otherwise, it calls CompactionPicker::Get to obtain a compaction task. If a task is present, it executes the compaction outside of the DB mutex. After compaction, it reacquires the DB mutex, creates a new superversion, and updates the DBImpl superversion. You can assume that the number of SSTables is small, allowing you to iterate through each SSTable and copy their pointers to the new superversion. The DB mutex should only be used for metadata operations. You must avoid performing the compaction process under the DB mutex. The code is in lsm.cpp and lsm.hpp .","title":"DBImpl::CompactionThread"},{"location":"p1/part2/#remove-old-sstables","text":"Utilize SetRemoveTag to set the remove_tag_ to true. When the destructor of SSTable is invoked, it checks the tag and determines whether to remove the file. This is safe as the destructor is called only when the SSTable is not in use.","title":"Remove old SSTables"},{"location":"p1/part2/#test","text":"TODO","title":"Test"},{"location":"p1/part3/","text":"Part 3 TODO","title":"Part 3"},{"location":"p1/part3/#part-3","text":"TODO","title":"Part 3"}]}