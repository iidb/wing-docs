{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Wing Wing","title":"Home"},{"location":"#wing","text":"Wing","title":"Wing"},{"location":"p1/overview/","text":"LSM Basic The code is in src/storage/lsm . The architecture of the LSM-tree in Wing is as follows. DBImpl : At the highest level, the DBImpl is the primary component responsible for interacting with users. It references the most recent SuperVersion of the database. It is in lsm.hpp . SuperVersion : It includes a MemTable, a list of immutable MemTables and the on-disk LSM-tree Version , which together represent the current state of the database. It is in version.hpp . MemTable : An in-memory ordered data structure. It is flushed to disk when it reaches its capacity. It is in memtable.hpp . Version : An array of levels, representing the on-disk LSM-tree. It is in version.hpp . Level : It is composed of one or more sorted runs. It is in level.hpp . SortedRun : It can be viewed as a sorted key-value array which is divided into several SSTables. It is in level.hpp . SSTable : It is composed of data blocks, an index, bloom filter and metadata. It is in sst.hpp . Block : It stores records. It is in block.hpp . Record Format Records in the database are structured as (key, seq, type, value) tuple, where seq denotes the timestamp (or sequence number) and type denotes the record type. A record with type=RecordType::Value represents the key-value pair at the timestamp seq . When type equals to RecordType::Deletion , the record indicates that the key has been marked for deletion at the timestamp seq . (key, seq, type) is called the internal key of record (see storage/lsm/format.hpp ) because seq and type are invisible to users. We can define a comparing function to sort them: for two internal keys (key0, seq0, type0) and (key1, seq1, type1) , the former is smaller than the latter if and only if key0 < key1 or key0 == key1 && seq0 > seq1 . With this comparing function, for (key, seq) , the newest record with the same key and a sequence number seq0 <= seq is the first record (key0, seq0) with (key, seq) <= (key0, seq0) . Get DBImpl::Get(key, seq, &value_str) function is designed to retrieve records from the database. It looks for the first record (key0, seq0, type0) satisfying key0 == key && seq0 <= seq . If the record is a record with type RecordType::Deletion or no such record exists, the function returns false, indicating the requested value is not found. If a record with type RecordType::Value is found, the function returns true and copies the associated value into value_str . The process of Get is: Check if MemTable has the record. If not, check if immutable MemTables have the record. It checks from the newest immutable MemTable to the oldest immutable MemTable. It stops once it finds the record. If they do not have the record, proceed to check the on-disk LSM-tree. Check if Level 0 has the record, then Level 1, 2, and so on. For each level, it performs a binary search to find the SSTable that possibly has the record. Then it queries the bloom filter. If further inquiry is necessary, it performs a binary search on the SSTable's index to find the data block. It reads the data block from the disk, and performs a binary search to find the record. Put and Delete DBImpl::Put(key, seq) creates a new record (key, seq, RecordType::Value, value) and DBImpl::Del(key, seq) creates a new record (key, seq, RecordType::Deletion) . Once a record is created, it is inserted to the MemTable. For convenience, a lock is employed to ensure that only a single writer can perform operations at any given time. If the MemTable reaches its capacity, it creates a new superversion and moves the MemTable to the immutable MemTable list and create a new MemTable. The database has 2 threads to persist the data to disk: the flush thread and the compaction thread. The flush thread is awakened whenever a new immutable MemTable is created. It flushes the immutable MemTables to the first level (Level 0) of the LSM-tree. Every time an immutable Memtable is flushed, the compaction thread is awakened. It acquires new compaction tasks through CompactionPicker::Get . Once it has tasks, it proceeds to execute them and subsequently updates the superversion. Scan The database supports range scans. DBImpl::Begin() returns an iterator positioned to the beginning of the data, while DBImpl::Seek(key, seq) returns an iterator positioned to the first record (key0, seq0, type0) satisfying (key, seq) <= (key0, seq0) . Scan operations are performed in a snapshot. When a DBIterator is created, it stores the current sequence number. It can only see the records with sequence number smaller than the stored sequence number. The architecture of iterators is as follows. BlockIterator is the iterator on data blocks. SSTableIterator is the iterator on SSTables and contains a BlockIterator . SortedRunIterator is the iterator on sorted runs and contains a SSTableIterator . SuperVersionIterator is the iterator on superversions, it contains all the SortedRunIterator s and MemTableIterator s using IteratorHeap , which maintains the record with the minimum internal key by maintaining iterators in a heap. There is no LevelIterator or VersionIterator because it is inefficient to maintain two IteratorHeap s. The DBIterator operates at the highest level, merging records with the same key and skipping the keys which are marked deleted. The interfaces of Iterator can be found in storage/lsm/iterator.hpp . Here is an example of usage: DBIterator it = ...; // create the iterator while (it.Valid()) { // Read key and value of the current entry auto key = it.key(); auto value = it.value(); // output key and value DB_INFO(\"{}, {}\", key, value); // Move to the next entry it.Next(); // After moving, key and value may be invalid because they are `Slice`s, // i.e. references to a internal buffer in `it`. }","title":"Overview"},{"location":"p1/overview/#lsm-basic","text":"The code is in src/storage/lsm . The architecture of the LSM-tree in Wing is as follows. DBImpl : At the highest level, the DBImpl is the primary component responsible for interacting with users. It references the most recent SuperVersion of the database. It is in lsm.hpp . SuperVersion : It includes a MemTable, a list of immutable MemTables and the on-disk LSM-tree Version , which together represent the current state of the database. It is in version.hpp . MemTable : An in-memory ordered data structure. It is flushed to disk when it reaches its capacity. It is in memtable.hpp . Version : An array of levels, representing the on-disk LSM-tree. It is in version.hpp . Level : It is composed of one or more sorted runs. It is in level.hpp . SortedRun : It can be viewed as a sorted key-value array which is divided into several SSTables. It is in level.hpp . SSTable : It is composed of data blocks, an index, bloom filter and metadata. It is in sst.hpp . Block : It stores records. It is in block.hpp .","title":"LSM Basic"},{"location":"p1/overview/#record-format","text":"Records in the database are structured as (key, seq, type, value) tuple, where seq denotes the timestamp (or sequence number) and type denotes the record type. A record with type=RecordType::Value represents the key-value pair at the timestamp seq . When type equals to RecordType::Deletion , the record indicates that the key has been marked for deletion at the timestamp seq . (key, seq, type) is called the internal key of record (see storage/lsm/format.hpp ) because seq and type are invisible to users. We can define a comparing function to sort them: for two internal keys (key0, seq0, type0) and (key1, seq1, type1) , the former is smaller than the latter if and only if key0 < key1 or key0 == key1 && seq0 > seq1 . With this comparing function, for (key, seq) , the newest record with the same key and a sequence number seq0 <= seq is the first record (key0, seq0) with (key, seq) <= (key0, seq0) .","title":"Record Format"},{"location":"p1/overview/#get","text":"DBImpl::Get(key, seq, &value_str) function is designed to retrieve records from the database. It looks for the first record (key0, seq0, type0) satisfying key0 == key && seq0 <= seq . If the record is a record with type RecordType::Deletion or no such record exists, the function returns false, indicating the requested value is not found. If a record with type RecordType::Value is found, the function returns true and copies the associated value into value_str . The process of Get is: Check if MemTable has the record. If not, check if immutable MemTables have the record. It checks from the newest immutable MemTable to the oldest immutable MemTable. It stops once it finds the record. If they do not have the record, proceed to check the on-disk LSM-tree. Check if Level 0 has the record, then Level 1, 2, and so on. For each level, it performs a binary search to find the SSTable that possibly has the record. Then it queries the bloom filter. If further inquiry is necessary, it performs a binary search on the SSTable's index to find the data block. It reads the data block from the disk, and performs a binary search to find the record.","title":"Get"},{"location":"p1/overview/#put-and-delete","text":"DBImpl::Put(key, seq) creates a new record (key, seq, RecordType::Value, value) and DBImpl::Del(key, seq) creates a new record (key, seq, RecordType::Deletion) . Once a record is created, it is inserted to the MemTable. For convenience, a lock is employed to ensure that only a single writer can perform operations at any given time. If the MemTable reaches its capacity, it creates a new superversion and moves the MemTable to the immutable MemTable list and create a new MemTable. The database has 2 threads to persist the data to disk: the flush thread and the compaction thread. The flush thread is awakened whenever a new immutable MemTable is created. It flushes the immutable MemTables to the first level (Level 0) of the LSM-tree. Every time an immutable Memtable is flushed, the compaction thread is awakened. It acquires new compaction tasks through CompactionPicker::Get . Once it has tasks, it proceeds to execute them and subsequently updates the superversion.","title":"Put and Delete"},{"location":"p1/overview/#scan","text":"The database supports range scans. DBImpl::Begin() returns an iterator positioned to the beginning of the data, while DBImpl::Seek(key, seq) returns an iterator positioned to the first record (key0, seq0, type0) satisfying (key, seq) <= (key0, seq0) . Scan operations are performed in a snapshot. When a DBIterator is created, it stores the current sequence number. It can only see the records with sequence number smaller than the stored sequence number. The architecture of iterators is as follows. BlockIterator is the iterator on data blocks. SSTableIterator is the iterator on SSTables and contains a BlockIterator . SortedRunIterator is the iterator on sorted runs and contains a SSTableIterator . SuperVersionIterator is the iterator on superversions, it contains all the SortedRunIterator s and MemTableIterator s using IteratorHeap , which maintains the record with the minimum internal key by maintaining iterators in a heap. There is no LevelIterator or VersionIterator because it is inefficient to maintain two IteratorHeap s. The DBIterator operates at the highest level, merging records with the same key and skipping the keys which are marked deleted. The interfaces of Iterator can be found in storage/lsm/iterator.hpp . Here is an example of usage: DBIterator it = ...; // create the iterator while (it.Valid()) { // Read key and value of the current entry auto key = it.key(); auto value = it.value(); // output key and value DB_INFO(\"{}, {}\", key, value); // Move to the next entry it.Next(); // After moving, key and value may be invalid because they are `Slice`s, // i.e. references to a internal buffer in `it`. }","title":"Scan"},{"location":"p1/part1/","text":"Part 1 In part 1, you will implement BlockIterator , BlockBuilder , SSTable , SSTableIterator and SSTableBuilder . SortedRun , SortedRunIterator . IteratorHeap . SuperVersion , SuperVersionIterator and Version . Each class contains some incomplete methods. You may add fields and methods as needed, but do not remove any existing fields or remove public methods, nor change the names of the methods. Block Block stores internal keys and values. If you do not have time to design complex formats such as a compressed format, we highly recommend you to implement the simplest format as follows: where the block is divided into two parts, the first part consists of key-value pairs, while the second part is an array of offsets to the key-value pairs. The key length and value length should be stored in 4 bytes (refer to offset_t in lsm/common.hpp ) or less. BlockIterator takes a pointer to the beginning of the Block (which is stored in a buffer) and the BlockHandle of the Block . You can obtain useful information such as the number of key-value pairs and the size of the Block in BlockHandle . BlockIterator::Seek(user_key, seq) finds the first record larger than (user_key, seq) and moves to it (refer to the definition of the comparison operator in storage/lsm/format.hpp ). BlockIterator::SeekToFirst moves the iterator to the beginning. You can find the comments for Next() , key() , value() and Valid() in storage/lsm/iterator.hpp . BlockBuilder writes key-value pairs to the block until the block reaches the capacity (refer to block_size in storage/lsm/options.hpp , this parameter is passed in the constructor of BlockBuilder ). BlockBuilder::Append returns false if the block is full. You need to ensure that the size of the block do not exceed block_size . The offsets of key-value pairs are written after all the key-value pairs are written and BlockBuilder::FinishBlock is called, so you need to record the offsets while writing the data. The code is in block.hpp and block.cpp . Slice Note that `Slice is equivalent to std::string_view (C++17), which is a reference to a string. It does not allocate a std::string . You need to ensure that the referenced string is not incorrectly deallocated or modified. Test You can test it through test/test_lsm --gtest_filter=LSMTest.BlockTest SSTable You can implement the format as follows: where data blocks are Block . The index consists of the last key and the BlockHandle of each Block , as defined in IndexValue in storage/lsm/format.hpp . It is utilized to locate data block in SSTable::Get , SSTable::Seek and SSTableIterator::Seek . It is preloaded to the memory when opening the SSTable. The bloom filter is used to test whether a key may exist in the SSTable during SSTable::Get . It is also preloaded to the memory. You will implement SSTableBuilder::Append and SSTableBuilder::Finish while maintaining the information about the SSTable: index_data_ (the index data), index_offset_ (the offset of the index block), bloom_filter_offset_ (the offset of the bloom filter), largest_key_ and smallest_key_ (which represent the key range of the SSTable), key_hashes_ . Once a SSTable is created, the information of the SSTable is transferred to the SSTable structure. You can use BlockBuilder to build data blocks. After writing all the key-value pairs, you can write the index data and the metadata to the file. Since we assume that we preload the index data when we open the SSTable, there is no need to use Block to store index data. The code is in sst.cpp and sst.hpp . FileWriter You should use FileWriter to implement SSTableBuilder , BlockBuilder . It collects data and writes them to disk in batch. FileWriter provides two methods WriteValue<T> and WriteString . You can use WriteValue<T> to copy a value of type T to the file. T is a template parameter, it can be uint64_t , float , or structured data which do not have pointers, such as std::pair<uint64_t, uint64_t> and BlockHandle . For string data, you can use WriteString . It only writes the string data, for example, if the string is abc , then it writes 3 bytes a , b and c . Here is an example of usage: std::string str(\"114514\"); writer.WriteValue<uint64_t>(str.length()); .WriteString(str); Note that you should call FileWriter::Flush when all things have been written. If you think the methods of FileWriter is difficult to use, you can modify them, but DO NOT read/write to a raw file handle in SSTableBuilder ! FileReader You can use FileReader to read metadata and index data while initializing SSTable . The method ReadValue and ReadString is similar to WriteValue and WriteString . Here is an example of usage: // Read the string \"114514\" reader.Seek(offset); auto len = reader.ReadValue<uint64_t>(); auto str = reader.ReadString(len); Bloom filter You will build a bloom filter for each SSTable. If you are not familiar with bloom filter, you can read about it in resources such as link . Basically, bloom filter is a bit array. For each key, it set some bits to 1. The positions of these bits are calculated using hash functions. Then, for each key, if all the corresponding bits are 1, the key may exist, otherwise it does not. We have implemented a bloom filter for you, which can be found in common/bloomfilter.hpp and common/bloomfilter.cpp . BloomFilter::Create create a bloom filter. BloomFilter::Add add a key to the bloom filter. Since we only use the hash of keys, you can pass the hash to BloomFilter::Add . BloomFilter::Find checks if a key may exist in the bloom filter. It can also accept the hash of keys. In SSTableBuilder , you should record the hashes of keys in SSTableBuilder::Append and use them to build a bloom filter in SSTableBuilder::Finish . Test You can test it through test/test_lsm --gtest_filter=LSMTest.SSTableTest SortedRun SortedRun stores an array of SSTables. You will implement it based on SSTable and SSTableIterator . The code is in level.cpp and level.hpp . Test You can test it through test/test_lsm --gtest_filter=LSMTest.SortedRunTest IteratorHeap The IteratorHeap structure is used when performing merge-sort on multiple sorted runs. IteratorHeap takes references to the iterators, so you need to store the iterator in another area and pass the reference to it. The usage of IteratorHeap is as follows: First, call IteratorHeap::Push to pass references to the iterators to it. Then, if it is necessary, call IteratorHeap::Build to do some preprocessing. Then, you can use Next , key , value , Valid as an ordinary iterator. It returns the minimum record each time and call Next on the corresponding iterator. We recommend you to use a heap to maintain the minimum record. You can use std::priority_queue or implement your own. The code is in iterator_heap.hpp . Note that IteratorHeap is a template class, if you are not familiar with it, you can read about templates in resources such as link . Test You can test it through test/test_lsm --gtest_filter=LSMTest.IteratorHeapTest SuperVersion After you implement SortedRun , SortedRunIterator and IteratorHeap , implementing SuperVersion should be straightforward. The code is in version.cpp and version.hpp . Test You can test it through test/test_lsm --gtest_filter=LSMTest.SuperVersionTest Smart Pointers We use smart pointers to manage reference counts for SSTables and sorted runs. If you are not familiar with them, you can read about smart pointers in resources such as link . DO NOT delete them! We rely on reference counts to support multiversion concurrency control. Submit make submit in the build directory to create submission.zip and submit it to autolab.","title":"Part 1"},{"location":"p1/part1/#part-1","text":"In part 1, you will implement BlockIterator , BlockBuilder , SSTable , SSTableIterator and SSTableBuilder . SortedRun , SortedRunIterator . IteratorHeap . SuperVersion , SuperVersionIterator and Version . Each class contains some incomplete methods. You may add fields and methods as needed, but do not remove any existing fields or remove public methods, nor change the names of the methods.","title":"Part 1"},{"location":"p1/part1/#block","text":"Block stores internal keys and values. If you do not have time to design complex formats such as a compressed format, we highly recommend you to implement the simplest format as follows: where the block is divided into two parts, the first part consists of key-value pairs, while the second part is an array of offsets to the key-value pairs. The key length and value length should be stored in 4 bytes (refer to offset_t in lsm/common.hpp ) or less. BlockIterator takes a pointer to the beginning of the Block (which is stored in a buffer) and the BlockHandle of the Block . You can obtain useful information such as the number of key-value pairs and the size of the Block in BlockHandle . BlockIterator::Seek(user_key, seq) finds the first record larger than (user_key, seq) and moves to it (refer to the definition of the comparison operator in storage/lsm/format.hpp ). BlockIterator::SeekToFirst moves the iterator to the beginning. You can find the comments for Next() , key() , value() and Valid() in storage/lsm/iterator.hpp . BlockBuilder writes key-value pairs to the block until the block reaches the capacity (refer to block_size in storage/lsm/options.hpp , this parameter is passed in the constructor of BlockBuilder ). BlockBuilder::Append returns false if the block is full. You need to ensure that the size of the block do not exceed block_size . The offsets of key-value pairs are written after all the key-value pairs are written and BlockBuilder::FinishBlock is called, so you need to record the offsets while writing the data. The code is in block.hpp and block.cpp .","title":"Block"},{"location":"p1/part1/#slice","text":"Note that `Slice is equivalent to std::string_view (C++17), which is a reference to a string. It does not allocate a std::string . You need to ensure that the referenced string is not incorrectly deallocated or modified.","title":"Slice"},{"location":"p1/part1/#test","text":"You can test it through test/test_lsm --gtest_filter=LSMTest.BlockTest","title":"Test"},{"location":"p1/part1/#sstable","text":"You can implement the format as follows: where data blocks are Block . The index consists of the last key and the BlockHandle of each Block , as defined in IndexValue in storage/lsm/format.hpp . It is utilized to locate data block in SSTable::Get , SSTable::Seek and SSTableIterator::Seek . It is preloaded to the memory when opening the SSTable. The bloom filter is used to test whether a key may exist in the SSTable during SSTable::Get . It is also preloaded to the memory. You will implement SSTableBuilder::Append and SSTableBuilder::Finish while maintaining the information about the SSTable: index_data_ (the index data), index_offset_ (the offset of the index block), bloom_filter_offset_ (the offset of the bloom filter), largest_key_ and smallest_key_ (which represent the key range of the SSTable), key_hashes_ . Once a SSTable is created, the information of the SSTable is transferred to the SSTable structure. You can use BlockBuilder to build data blocks. After writing all the key-value pairs, you can write the index data and the metadata to the file. Since we assume that we preload the index data when we open the SSTable, there is no need to use Block to store index data. The code is in sst.cpp and sst.hpp .","title":"SSTable"},{"location":"p1/part1/#filewriter","text":"You should use FileWriter to implement SSTableBuilder , BlockBuilder . It collects data and writes them to disk in batch. FileWriter provides two methods WriteValue<T> and WriteString . You can use WriteValue<T> to copy a value of type T to the file. T is a template parameter, it can be uint64_t , float , or structured data which do not have pointers, such as std::pair<uint64_t, uint64_t> and BlockHandle . For string data, you can use WriteString . It only writes the string data, for example, if the string is abc , then it writes 3 bytes a , b and c . Here is an example of usage: std::string str(\"114514\"); writer.WriteValue<uint64_t>(str.length()); .WriteString(str); Note that you should call FileWriter::Flush when all things have been written. If you think the methods of FileWriter is difficult to use, you can modify them, but DO NOT read/write to a raw file handle in SSTableBuilder !","title":"FileWriter"},{"location":"p1/part1/#filereader","text":"You can use FileReader to read metadata and index data while initializing SSTable . The method ReadValue and ReadString is similar to WriteValue and WriteString . Here is an example of usage: // Read the string \"114514\" reader.Seek(offset); auto len = reader.ReadValue<uint64_t>(); auto str = reader.ReadString(len);","title":"FileReader"},{"location":"p1/part1/#bloom-filter","text":"You will build a bloom filter for each SSTable. If you are not familiar with bloom filter, you can read about it in resources such as link . Basically, bloom filter is a bit array. For each key, it set some bits to 1. The positions of these bits are calculated using hash functions. Then, for each key, if all the corresponding bits are 1, the key may exist, otherwise it does not. We have implemented a bloom filter for you, which can be found in common/bloomfilter.hpp and common/bloomfilter.cpp . BloomFilter::Create create a bloom filter. BloomFilter::Add add a key to the bloom filter. Since we only use the hash of keys, you can pass the hash to BloomFilter::Add . BloomFilter::Find checks if a key may exist in the bloom filter. It can also accept the hash of keys. In SSTableBuilder , you should record the hashes of keys in SSTableBuilder::Append and use them to build a bloom filter in SSTableBuilder::Finish .","title":"Bloom filter"},{"location":"p1/part1/#test_1","text":"You can test it through test/test_lsm --gtest_filter=LSMTest.SSTableTest","title":"Test"},{"location":"p1/part1/#sortedrun","text":"SortedRun stores an array of SSTables. You will implement it based on SSTable and SSTableIterator . The code is in level.cpp and level.hpp .","title":"SortedRun"},{"location":"p1/part1/#test_2","text":"You can test it through test/test_lsm --gtest_filter=LSMTest.SortedRunTest","title":"Test"},{"location":"p1/part1/#iteratorheap","text":"The IteratorHeap structure is used when performing merge-sort on multiple sorted runs. IteratorHeap takes references to the iterators, so you need to store the iterator in another area and pass the reference to it. The usage of IteratorHeap is as follows: First, call IteratorHeap::Push to pass references to the iterators to it. Then, if it is necessary, call IteratorHeap::Build to do some preprocessing. Then, you can use Next , key , value , Valid as an ordinary iterator. It returns the minimum record each time and call Next on the corresponding iterator. We recommend you to use a heap to maintain the minimum record. You can use std::priority_queue or implement your own. The code is in iterator_heap.hpp . Note that IteratorHeap is a template class, if you are not familiar with it, you can read about templates in resources such as link .","title":"IteratorHeap"},{"location":"p1/part1/#test_3","text":"You can test it through test/test_lsm --gtest_filter=LSMTest.IteratorHeapTest","title":"Test"},{"location":"p1/part1/#superversion","text":"After you implement SortedRun , SortedRunIterator and IteratorHeap , implementing SuperVersion should be straightforward. The code is in version.cpp and version.hpp .","title":"SuperVersion"},{"location":"p1/part1/#test_4","text":"You can test it through test/test_lsm --gtest_filter=LSMTest.SuperVersionTest","title":"Test"},{"location":"p1/part1/#smart-pointers","text":"We use smart pointers to manage reference counts for SSTables and sorted runs. If you are not familiar with them, you can read about smart pointers in resources such as link . DO NOT delete them! We rely on reference counts to support multiversion concurrency control.","title":"Smart Pointers"},{"location":"p1/part1/#submit","text":"make submit in the build directory to create submission.zip and submit it to autolab.","title":"Submit"},{"location":"p1/part2/","text":"Part 2 In part 2, you will implement compaction mechanism. You will implement: CompactionJob . This component receives an iterator and persists its output as a list of SSTables. It is utilized in both DBImpl::FlushThread and DBImpl::CompactionThread . LeveledCompactionPicker , which is derived from CompactionPicker . It generates a new compaction task. The parameters for the compaction task are stored in Compaction . It returns nullptr if no compaction is required for the LSM-tree. DBImpl::CompactionThread . This thread manages the compaction process and updates the superversion. You may refer to the implementation of DBImpl::FlushThread for guidance. You may need to use ulimit to increase the number of open file descriptors. (by default it is 1024, which is not enough). DBImpl::CompactionJob You will implement CompactionJob::Run. It receives an iterator and writes the iterator's output to disk. You should merge the records with the same key. The output is divided into SSTables, with the size of data blocks in SSTable not exceeding the target SSTable size (refer to sst_file_size in storage/lsm/options.hpp ). The actual SSTable size may be larger than the target SSTable size since we have index data, bloom filter and metadata. The code is in compaction_job.hpp . Test You can test it through test/test_lsm --gtest_filter=LSMTest.CompactionBasicTest Leveled compaction strategy You will implement the leveled compaction strategy. This strategy is the default strategy of RocksDB. The leveled compaction strategy in Wing is as follows: Suppose the size ratio is T T , and the size limit of Level 0 is B B . The size limit of Level 1, 2, 3 \\cdots \\cdots is BT,BT^2,BT^3\\cdots BT,BT^2,BT^3\\cdots Level 0 consists of multiple sorted runs flushed by DBImpl::FlushThread , each sorted run has 1 or 2 SSTables. If the number of sorted runs is larger than 4, all the sorted runs are compacted to the next level. If the number of sorted runs reaches 20, then DBImpl::FlushThread stops to flush until they are compacted to the next level. Level 1, 2, 3 \\cdots \\cdots consists of only one sorted run. If one of them reaches its capacity, it picks an SSTable with the minimum overlapping with the next level, and compact the SSTable with the next level. In LeveledCompactionPicker::Get, you must check for the existence of a compaction task. If one exists, you must create and return a std::unique_ptr<Compaction> . Otherwise, return a nullptr. The code is in compaction_picker.hpp , compaction_picker.cpp , compaction.hpp . DBImpl::CompactionThread Put/Del operation The Put/Del operation inserts a record into the LSM-tree. The key is converted to an internal key by adding the current sequence number and record type ( RecordType::Value or RecordType::Deletion ). Initially, it is inserted into the memtable. If the memtable reaches its capacity, it is appended to the list of immutable memtables. Then it nofities the flush thread. Then it installs the superversion (refer to DBImpl::SwitchMemtable ). The flush thread waits for the signal and fetches the list of immutable memtables. It flushes them (through CompactionJob ) to sorted runs. Once the sorted runs are created, it creates a new superversion, installs the superversion, and notifies the compaction thread (refer to DBImpl::FlushThread ). The compaction thread waits for the signal from the flush thread. Upon awakening, it checks the levels and attempts to find a compaction task (refer to CompactionPicker::Get and Compaction in lsm/compaction_pick.hpp and lsm/compaction.hpp ). For example, it may find that Level 0 is too large, so it creates a compaction task: compacting some SSTable files from Level 0 to Level 1. After new SSTable files are created, it creates a new superversion, installs the superversion and looks for compaction tasks again. It is possible that multiple compactions occur when one immutable memtable is flushed. It also add removal tags to useless SSTables, so that they will be removed while destruction. Locks in LSM-tree There are 3 locks in LSM-tree. We use concurrency primitives in C++, including std::mutex , std::unique_lock , std::shared_mutex (C++17), std::shared_lock (C++17), std::condition_variable . The first is db_mutex_ . This mutex is used to protect the process of operating metadata (e.g. switching memtables, creating new superversion and installing new superversions). The second is write_mutex_ . This mutex is used to protect Put operations. The third is sv_mutex_ . This mutex is used to protect the reference and installation of the superversion pointer. Multiversion Concurrency Control in LSM-tree In LSM-tree, Put operations do not block Get / Scan (implemented by DBIterator ) operations. This is achieved by supporting multiple superversions simultaneously. Each superversion has a reference count which is maintained by std::shared_ptr , the SSTables and the sorted runs in one superversion will not be removed if the reference count does not decrease to 0. For Get and Scan operations, a superversion is referenced, and the data accessed within this superversion remains consistent regardless of new superversions created by the Put / FlushThread / CompactionThread . Task You will implement DBImpl::CompactionThread . The compaction thread awaits signals from the flush thread or the deconstructor via the condition variable compact_cv_ . Upon being awakened, it first checks stop_signal_ . If stop_signal_ is true, it stops immediately. Otherwise, it calls CompactionPicker::Get to obtain a compaction task. If a task is present, it executes the compaction outside of the DB mutex. After compaction, it reacquires the DB mutex, creates a new superversion, and updates the DBImpl superversion. You can assume that the number of SSTables is small, allowing you to iterate through each SSTable and copy their pointers to the new superversion. You also need to set compaction_flag_ to true if you are not waiting for compact_cv_ , like flush_flag_ in DBImpl::FlushThread . More specifically, you need to write something like: void DBImpl::CompactionThread() { while (!stop_signal_) { std::unique_lock lck(db_mutex_); // Check if it has to stop. // It has to stop when the LSM-tree shutdowns. if (stop_signal_) { compact_flag_ = false; return; } std::unique_ptr<Compaction> compaction = /* A new compaction task */ if (!compaction) { compact_flag_ = false; compact_cv_.wait(lck); continue; } compact_flag_ = true; // Do some other things db_mutex_.unlock(); // Do compaction db_mutex_.lock(); // Create a new superversion and install it } } The DB mutex should only be used for metadata operations. You must avoid performing the compaction process under the DB mutex. The code is in lsm.cpp and lsm.hpp . Remove old SSTables Utilize SetRemoveTag to set the remove_tag_ to true. When the destructor of SSTable is invoked, it checks the tag and determines whether to remove the file. This is safe as the destructor is called only when the SSTable is not in use. Test You can test all the components through test/test_lsm --gtest_filter=LSMTest.LSMBasicTest:LSMTest.LSMSmallGetTest:LSMTest.LSMSmallScanTest:LSMTest.LSMSmallMultithreadGetPutTest:LSMTest.LSMSaveTest:LSMTest.LSMBigScanTest:LSMTest.LSMDuplicateKeyTest:LSMTest.LeveledCompactionTest or, you can just use test/test_lsm --gtest_filter=LSMTest.LSM*:LSMTest.LeveledCompactionTest","title":"Part 2"},{"location":"p1/part2/#part-2","text":"In part 2, you will implement compaction mechanism. You will implement: CompactionJob . This component receives an iterator and persists its output as a list of SSTables. It is utilized in both DBImpl::FlushThread and DBImpl::CompactionThread . LeveledCompactionPicker , which is derived from CompactionPicker . It generates a new compaction task. The parameters for the compaction task are stored in Compaction . It returns nullptr if no compaction is required for the LSM-tree. DBImpl::CompactionThread . This thread manages the compaction process and updates the superversion. You may refer to the implementation of DBImpl::FlushThread for guidance. You may need to use ulimit to increase the number of open file descriptors. (by default it is 1024, which is not enough).","title":"Part 2"},{"location":"p1/part2/#dbimplcompactionjob","text":"You will implement CompactionJob::Run. It receives an iterator and writes the iterator's output to disk. You should merge the records with the same key. The output is divided into SSTables, with the size of data blocks in SSTable not exceeding the target SSTable size (refer to sst_file_size in storage/lsm/options.hpp ). The actual SSTable size may be larger than the target SSTable size since we have index data, bloom filter and metadata. The code is in compaction_job.hpp .","title":"DBImpl::CompactionJob"},{"location":"p1/part2/#test","text":"You can test it through test/test_lsm --gtest_filter=LSMTest.CompactionBasicTest","title":"Test"},{"location":"p1/part2/#leveled-compaction-strategy","text":"You will implement the leveled compaction strategy. This strategy is the default strategy of RocksDB. The leveled compaction strategy in Wing is as follows: Suppose the size ratio is T T , and the size limit of Level 0 is B B . The size limit of Level 1, 2, 3 \\cdots \\cdots is BT,BT^2,BT^3\\cdots BT,BT^2,BT^3\\cdots Level 0 consists of multiple sorted runs flushed by DBImpl::FlushThread , each sorted run has 1 or 2 SSTables. If the number of sorted runs is larger than 4, all the sorted runs are compacted to the next level. If the number of sorted runs reaches 20, then DBImpl::FlushThread stops to flush until they are compacted to the next level. Level 1, 2, 3 \\cdots \\cdots consists of only one sorted run. If one of them reaches its capacity, it picks an SSTable with the minimum overlapping with the next level, and compact the SSTable with the next level. In LeveledCompactionPicker::Get, you must check for the existence of a compaction task. If one exists, you must create and return a std::unique_ptr<Compaction> . Otherwise, return a nullptr. The code is in compaction_picker.hpp , compaction_picker.cpp , compaction.hpp .","title":"Leveled compaction strategy"},{"location":"p1/part2/#dbimplcompactionthread","text":"","title":"DBImpl::CompactionThread"},{"location":"p1/part2/#putdel-operation","text":"The Put/Del operation inserts a record into the LSM-tree. The key is converted to an internal key by adding the current sequence number and record type ( RecordType::Value or RecordType::Deletion ). Initially, it is inserted into the memtable. If the memtable reaches its capacity, it is appended to the list of immutable memtables. Then it nofities the flush thread. Then it installs the superversion (refer to DBImpl::SwitchMemtable ). The flush thread waits for the signal and fetches the list of immutable memtables. It flushes them (through CompactionJob ) to sorted runs. Once the sorted runs are created, it creates a new superversion, installs the superversion, and notifies the compaction thread (refer to DBImpl::FlushThread ). The compaction thread waits for the signal from the flush thread. Upon awakening, it checks the levels and attempts to find a compaction task (refer to CompactionPicker::Get and Compaction in lsm/compaction_pick.hpp and lsm/compaction.hpp ). For example, it may find that Level 0 is too large, so it creates a compaction task: compacting some SSTable files from Level 0 to Level 1. After new SSTable files are created, it creates a new superversion, installs the superversion and looks for compaction tasks again. It is possible that multiple compactions occur when one immutable memtable is flushed. It also add removal tags to useless SSTables, so that they will be removed while destruction.","title":"Put/Del operation"},{"location":"p1/part2/#locks-in-lsm-tree","text":"There are 3 locks in LSM-tree. We use concurrency primitives in C++, including std::mutex , std::unique_lock , std::shared_mutex (C++17), std::shared_lock (C++17), std::condition_variable . The first is db_mutex_ . This mutex is used to protect the process of operating metadata (e.g. switching memtables, creating new superversion and installing new superversions). The second is write_mutex_ . This mutex is used to protect Put operations. The third is sv_mutex_ . This mutex is used to protect the reference and installation of the superversion pointer.","title":"Locks in LSM-tree"},{"location":"p1/part2/#multiversion-concurrency-control-in-lsm-tree","text":"In LSM-tree, Put operations do not block Get / Scan (implemented by DBIterator ) operations. This is achieved by supporting multiple superversions simultaneously. Each superversion has a reference count which is maintained by std::shared_ptr , the SSTables and the sorted runs in one superversion will not be removed if the reference count does not decrease to 0. For Get and Scan operations, a superversion is referenced, and the data accessed within this superversion remains consistent regardless of new superversions created by the Put / FlushThread / CompactionThread .","title":"Multiversion Concurrency Control in LSM-tree"},{"location":"p1/part2/#task","text":"You will implement DBImpl::CompactionThread . The compaction thread awaits signals from the flush thread or the deconstructor via the condition variable compact_cv_ . Upon being awakened, it first checks stop_signal_ . If stop_signal_ is true, it stops immediately. Otherwise, it calls CompactionPicker::Get to obtain a compaction task. If a task is present, it executes the compaction outside of the DB mutex. After compaction, it reacquires the DB mutex, creates a new superversion, and updates the DBImpl superversion. You can assume that the number of SSTables is small, allowing you to iterate through each SSTable and copy their pointers to the new superversion. You also need to set compaction_flag_ to true if you are not waiting for compact_cv_ , like flush_flag_ in DBImpl::FlushThread . More specifically, you need to write something like: void DBImpl::CompactionThread() { while (!stop_signal_) { std::unique_lock lck(db_mutex_); // Check if it has to stop. // It has to stop when the LSM-tree shutdowns. if (stop_signal_) { compact_flag_ = false; return; } std::unique_ptr<Compaction> compaction = /* A new compaction task */ if (!compaction) { compact_flag_ = false; compact_cv_.wait(lck); continue; } compact_flag_ = true; // Do some other things db_mutex_.unlock(); // Do compaction db_mutex_.lock(); // Create a new superversion and install it } } The DB mutex should only be used for metadata operations. You must avoid performing the compaction process under the DB mutex. The code is in lsm.cpp and lsm.hpp .","title":"Task"},{"location":"p1/part2/#remove-old-sstables","text":"Utilize SetRemoveTag to set the remove_tag_ to true. When the destructor of SSTable is invoked, it checks the tag and determines whether to remove the file. This is safe as the destructor is called only when the SSTable is not in use.","title":"Remove old SSTables"},{"location":"p1/part2/#test_1","text":"You can test all the components through test/test_lsm --gtest_filter=LSMTest.LSMBasicTest:LSMTest.LSMSmallGetTest:LSMTest.LSMSmallScanTest:LSMTest.LSMSmallMultithreadGetPutTest:LSMTest.LSMSaveTest:LSMTest.LSMBigScanTest:LSMTest.LSMDuplicateKeyTest:LSMTest.LeveledCompactionTest or, you can just use test/test_lsm --gtest_filter=LSMTest.LSM*:LSMTest.LeveledCompactionTest","title":"Test"},{"location":"p1/part3/","text":"Part 3: Tradeoff between range scan and compaction You should submit your code and report on the Web Learning \u7f51\u7edc\u5b66\u5802. In the report, you need to write your answers to the problems. Problem 1: lazy leveling (3pts) We previously implemented the leveling compaction policy: there is only one sorted run in each level, and the size of the latter level is T T times the size of the former level. Therefore, the write amplification to compaction one key to the next level is T T . If there are L L levels, the write amplification is TL TL . Tiering is another compaction policy: there are at most T T sorted runs in each level, and when the number of sorted runs in a level reaches T T , all T T sorted runs will be merged (i.e., compacted) into a new sorted run in the next level. Since for each key, it can only be compacted from one level to the next level, a key will be compacted at most L L times if there are L L levels. Thus the write amplification of the tiering policy is O(L) O(L) . It is smaller than the write amplification of leveling strategy O(TL) O(TL) . However, the tiering policy suffers from high space amplification. In the worst case, there can be T T duplicate sorted runs in the last level, and the space amplification can be T T . It is unacceptable. Thus, lazy leveling is proposed. Lazy leveling combines the advantages of the leveling policy and the tiering policy. Suppose there are L L levels in total. Lazy leveling uses the tiering compaction policy in Level 1 1 , Level 2 2 , \\cdots \\cdots , Level L-1 L-1 to reduce the write amplification. The maximum number of sorted runs in these levels is T T . Lazy leveling limits the space amplification by allowing only one sorted run in the last level. When the number of sorted runs in Level 1 1 , 2 2 , \\cdots \\cdots , L-2 L-2 reaches T T , all these sorted runs in the respective level will be merged into a new sorted run in the next level. When the number of sorted runs in Level L-1 L-1 reaches T T , all sorted runs in it will be merged into the sorted run in Level L L . Here we analyze the write amplification of lazy leveling. Similar to the tiering policy, each non-last level contributes 1 1 to the write amplification. The last level uses the leveling compaction policy, therefore it contributes C C to the write amplification, where C C is the size ratio between Level L L and Level L-1 L-1 . Therefore, the total write amplification is L - 1 + C L - 1 + C . The write cost w w is (L - 1 + C)(input\\ size) (L - 1 + C)(input\\ size) . Your tasks are as follows: Implement lazy leveling in LazyLevelingCompactionPicker::Get . You can test it through test/test_lsm --gtest_filter=LSMTest.LazyLevelingCompactionTest . Please submit to autolab. Measure the write amplification in the test and compare it with the theoretical write amplification L - 1 + C L - 1 + C in the report. If they are different, please analyze the reason. Problem 2: find the best compaction policy (4pts) Range scan is a query type that retrieves all records in the given range. To scan a range, we first seek the begin key in all sorted runs, and then sequentially read subsequent records until the end of the range. In problem 2 and problem 3, we only consider short range scan (scan length \\leq 100 \\leq 100 ). We assume that for each sorted run, we read only one block. So the range scan cost for lazy leveling is (1 + T (L-1))(block\\ size) (1 + T (L-1))(block\\ size) , where 1 + T(L-1) 1 + T(L-1) is the number of sorted runs. We can generalize the lazy leveling compaction policy by allowing different maximum numbers of sorted runs in non-last levels. Specifically, for Level i i where i < L i < L , we designate the maximum number of sorted runs as k_i k_i . We model the total cost of compactions and range scans in the generalized lazy leveling policy as f(\\vec k, C) = w(\\vec k, C) + \\alpha r(\\vec k) f(\\vec k, C) = w(\\vec k, C) + \\alpha r(\\vec k) . The write cost is the I/O cost of writing data. It can be modeled by w(\\vec k, C) = (L - 1 + C)(input\\ size) w(\\vec k, C) = (L - 1 + C)(input\\ size) . The read cost r(\\vec k) r(\\vec k) is the I/O cost of N N range scans where N N is the number of input keys. You need to model the read cost and write cost. \\alpha \\alpha describes the workload: a small \\alpha \\alpha for a write-heavy workload and a large \\alpha \\alpha for a scan-heavy workload. Your task: given the size of the last level N N , the base level size F F , the workload parameter alpha alpha , find \\vec k \\vec k and C C that minimize f(\\vec k, C) f(\\vec k, C) and satisfy N = \\prod_{i=1}^{L-1} k_i F C N = \\prod_{i=1}^{L-1} k_i F C . You need to design an algorithm to calculate optimal \\vec k, C \\vec k, C based on parameters. More specifically, you need to implement FluidCompactionPicker::Get and adjust the maximum number of sorted runs in each level based on your algorithms. You may explore when and how to adjust the maximum number of sorted runs in each level. For example, you may calculate the optimal \\vec k \\vec k and C C for every 5 seconds and apply the changes only when the optimal \\vec k \\vec k or C C differs much from the current value. We provide a basic benchmark that can be executed by test/test_lsm --gtest_filter=LSMTest.Part3Benchmark1 . Your algorithm should outperform than the baseline. There is no need to submit to autolab due to the long execution time. Please write a report detailing the algorithm you have designed and implemented. Additionally, include a comprehensive comparison with other compaction policies. Compare your algorithm with other compaction policies, including leveling, tiering, and lazy leveling in problem 1. Furthermore, adjust the alpha value in the benchmark (passing different alpha value to Part3Benchmark function), and determine the range of alpha where your algorithm performs the best. The parameters in Part3Benchmark(alpha, N, scan_length) are: alpha value, N is the number of keys, scan_length is the length of range scan. scan_length is set to be larger than N in this problem to ensure that all sorted runs are accessed. The read cost is still calculated by (number of sorted runs)*(block size) regardless of long scan_length . The read cost is calculated in the benchmark function as follows: read cost = 0 write cost = 0 for T in range(10): insert 10% of key-value pairs read cost += (number of sorted runs) * (block size) * (number of inserted key pairs) write cost += (write cost of inserted key pairs) read cost /= 10 write cost /= 10 total cost = (read cost) * alpha + (write cost) You can get points as long as your solution is reasonable and well-founded. Problem 3: find the best compaction policy considering range filters (3pts) Similar to bloom filters, there are also range filters. They can determine whether keys exist within a specified range in a sorted run. It allows range scans to skip sorted runs without relevant keys, optimizing query performance. We assume that we have a perfect range filter which does not produce false positives. Using this range filter, we can calculate the read cost based on the expected number of sorted runs that need to read. We also assume that the length m m of range scan is always the same. Let the total size of LSM-tree be S S . Suppose there is a sorted run of size T T in the LSM-tree. Assuming that all the keys in the LSM-tree are unique and uniformly distributed, for a range scan of length m m , the probability that a key from the sorted run will be in the result of the range scan is 1 - \\prod_{i=0}^{m-1}\\frac{S-T-i}{S-i} 1 - \\prod_{i=0}^{m-1}\\frac{S-T-i}{S-i} . You can consider for the first key in the result of the range scan, the probability that the key is not in the sorted run is \\frac{S-T}{S} \\frac{S-T}{S} , and for the second key it is \\frac{S-T-1}{S-1} \\frac{S-T-1}{S-1} , and so on. This probability is approximately \\approx 1-(1-\\frac{T}{S})^m\\approx 1-e^{-mT/S} \\approx 1-(1-\\frac{T}{S})^m\\approx 1-e^{-mT/S} . Then the read cost can be calculated by r(\\vec k)=(\\sum_{T} 1-e^{-mT/S})(block\\ size) r(\\vec k)=(\\sum_{T} 1-e^{-mT/S})(block\\ size) . The write cost is the same as problem 2. The code of estimation is in Part3Benchmark function. Your task: given the size of the last level N N , the base level size F F , the workload parameter alpha alpha , and the range scan length m m , approximate the read cost and write cost, find \\vec k, C \\vec k, C that minimize f(\\vec k, C) = w(\\vec k, C) + \\alpha r(\\vec k) f(\\vec k, C) = w(\\vec k, C) + \\alpha r(\\vec k) and satisfy N = \\prod_{i=1}^{L-1} k_i C F N = \\prod_{i=1}^{L-1} k_i C F . You need to implement it in FluidCompactionPicker::Get . We provide a basic benchmark that can be executed by test/test_lsm --gtest_filter=LSMTest.Part3Benchmark2 . Your algorithm should outperform than the baseline. There is no need to submit to autolab due to the long execution time. Please write a report detailing the algorithm you have designed and implemented. Additionally, include a comprehensive comparison with other compaction policies. Compare your algorithm with other compaction policies, including leveling, tiering, and lazy leveling in problem 1. Furthermore, adjust the alpha value in the benchmark, and determine the range of alpha where your algorithm performs the best. The parameters in Part3Benchmark(alpha, N, scan_length) are: alpha value, N is the number of keys, scan_length is the length of range scan. scan_length is set to 100 by default. You can also pass different scan_length to this function. The read cost is calculated as follows: read cost = 0 write cost = 0 for T in range(10): insert 10% of key-value pairs read cost += (number of sorted runs that need to be accessed) * (block size) * (number of inserted key pairs) write cost += (write cost of inserted key pairs) read cost /= 10 write cost /= 10 total cost = (read cost) * alpha + (write cost) You can get points as long as your solution is reasonable and well-founded.","title":"Part 3"},{"location":"p1/part3/#part-3-tradeoff-between-range-scan-and-compaction","text":"You should submit your code and report on the Web Learning \u7f51\u7edc\u5b66\u5802. In the report, you need to write your answers to the problems.","title":"Part 3: Tradeoff between range scan and compaction"},{"location":"p1/part3/#problem-1-lazy-leveling-3pts","text":"We previously implemented the leveling compaction policy: there is only one sorted run in each level, and the size of the latter level is T T times the size of the former level. Therefore, the write amplification to compaction one key to the next level is T T . If there are L L levels, the write amplification is TL TL . Tiering is another compaction policy: there are at most T T sorted runs in each level, and when the number of sorted runs in a level reaches T T , all T T sorted runs will be merged (i.e., compacted) into a new sorted run in the next level. Since for each key, it can only be compacted from one level to the next level, a key will be compacted at most L L times if there are L L levels. Thus the write amplification of the tiering policy is O(L) O(L) . It is smaller than the write amplification of leveling strategy O(TL) O(TL) . However, the tiering policy suffers from high space amplification. In the worst case, there can be T T duplicate sorted runs in the last level, and the space amplification can be T T . It is unacceptable. Thus, lazy leveling is proposed. Lazy leveling combines the advantages of the leveling policy and the tiering policy. Suppose there are L L levels in total. Lazy leveling uses the tiering compaction policy in Level 1 1 , Level 2 2 , \\cdots \\cdots , Level L-1 L-1 to reduce the write amplification. The maximum number of sorted runs in these levels is T T . Lazy leveling limits the space amplification by allowing only one sorted run in the last level. When the number of sorted runs in Level 1 1 , 2 2 , \\cdots \\cdots , L-2 L-2 reaches T T , all these sorted runs in the respective level will be merged into a new sorted run in the next level. When the number of sorted runs in Level L-1 L-1 reaches T T , all sorted runs in it will be merged into the sorted run in Level L L . Here we analyze the write amplification of lazy leveling. Similar to the tiering policy, each non-last level contributes 1 1 to the write amplification. The last level uses the leveling compaction policy, therefore it contributes C C to the write amplification, where C C is the size ratio between Level L L and Level L-1 L-1 . Therefore, the total write amplification is L - 1 + C L - 1 + C . The write cost w w is (L - 1 + C)(input\\ size) (L - 1 + C)(input\\ size) . Your tasks are as follows: Implement lazy leveling in LazyLevelingCompactionPicker::Get . You can test it through test/test_lsm --gtest_filter=LSMTest.LazyLevelingCompactionTest . Please submit to autolab. Measure the write amplification in the test and compare it with the theoretical write amplification L - 1 + C L - 1 + C in the report. If they are different, please analyze the reason.","title":"Problem 1: lazy leveling (3pts)"},{"location":"p1/part3/#problem-2-find-the-best-compaction-policy-4pts","text":"Range scan is a query type that retrieves all records in the given range. To scan a range, we first seek the begin key in all sorted runs, and then sequentially read subsequent records until the end of the range. In problem 2 and problem 3, we only consider short range scan (scan length \\leq 100 \\leq 100 ). We assume that for each sorted run, we read only one block. So the range scan cost for lazy leveling is (1 + T (L-1))(block\\ size) (1 + T (L-1))(block\\ size) , where 1 + T(L-1) 1 + T(L-1) is the number of sorted runs. We can generalize the lazy leveling compaction policy by allowing different maximum numbers of sorted runs in non-last levels. Specifically, for Level i i where i < L i < L , we designate the maximum number of sorted runs as k_i k_i . We model the total cost of compactions and range scans in the generalized lazy leveling policy as f(\\vec k, C) = w(\\vec k, C) + \\alpha r(\\vec k) f(\\vec k, C) = w(\\vec k, C) + \\alpha r(\\vec k) . The write cost is the I/O cost of writing data. It can be modeled by w(\\vec k, C) = (L - 1 + C)(input\\ size) w(\\vec k, C) = (L - 1 + C)(input\\ size) . The read cost r(\\vec k) r(\\vec k) is the I/O cost of N N range scans where N N is the number of input keys. You need to model the read cost and write cost. \\alpha \\alpha describes the workload: a small \\alpha \\alpha for a write-heavy workload and a large \\alpha \\alpha for a scan-heavy workload. Your task: given the size of the last level N N , the base level size F F , the workload parameter alpha alpha , find \\vec k \\vec k and C C that minimize f(\\vec k, C) f(\\vec k, C) and satisfy N = \\prod_{i=1}^{L-1} k_i F C N = \\prod_{i=1}^{L-1} k_i F C . You need to design an algorithm to calculate optimal \\vec k, C \\vec k, C based on parameters. More specifically, you need to implement FluidCompactionPicker::Get and adjust the maximum number of sorted runs in each level based on your algorithms. You may explore when and how to adjust the maximum number of sorted runs in each level. For example, you may calculate the optimal \\vec k \\vec k and C C for every 5 seconds and apply the changes only when the optimal \\vec k \\vec k or C C differs much from the current value. We provide a basic benchmark that can be executed by test/test_lsm --gtest_filter=LSMTest.Part3Benchmark1 . Your algorithm should outperform than the baseline. There is no need to submit to autolab due to the long execution time. Please write a report detailing the algorithm you have designed and implemented. Additionally, include a comprehensive comparison with other compaction policies. Compare your algorithm with other compaction policies, including leveling, tiering, and lazy leveling in problem 1. Furthermore, adjust the alpha value in the benchmark (passing different alpha value to Part3Benchmark function), and determine the range of alpha where your algorithm performs the best. The parameters in Part3Benchmark(alpha, N, scan_length) are: alpha value, N is the number of keys, scan_length is the length of range scan. scan_length is set to be larger than N in this problem to ensure that all sorted runs are accessed. The read cost is still calculated by (number of sorted runs)*(block size) regardless of long scan_length . The read cost is calculated in the benchmark function as follows: read cost = 0 write cost = 0 for T in range(10): insert 10% of key-value pairs read cost += (number of sorted runs) * (block size) * (number of inserted key pairs) write cost += (write cost of inserted key pairs) read cost /= 10 write cost /= 10 total cost = (read cost) * alpha + (write cost) You can get points as long as your solution is reasonable and well-founded.","title":"Problem 2: find the best compaction policy (4pts)"},{"location":"p1/part3/#problem-3-find-the-best-compaction-policy-considering-range-filters-3pts","text":"Similar to bloom filters, there are also range filters. They can determine whether keys exist within a specified range in a sorted run. It allows range scans to skip sorted runs without relevant keys, optimizing query performance. We assume that we have a perfect range filter which does not produce false positives. Using this range filter, we can calculate the read cost based on the expected number of sorted runs that need to read. We also assume that the length m m of range scan is always the same. Let the total size of LSM-tree be S S . Suppose there is a sorted run of size T T in the LSM-tree. Assuming that all the keys in the LSM-tree are unique and uniformly distributed, for a range scan of length m m , the probability that a key from the sorted run will be in the result of the range scan is 1 - \\prod_{i=0}^{m-1}\\frac{S-T-i}{S-i} 1 - \\prod_{i=0}^{m-1}\\frac{S-T-i}{S-i} . You can consider for the first key in the result of the range scan, the probability that the key is not in the sorted run is \\frac{S-T}{S} \\frac{S-T}{S} , and for the second key it is \\frac{S-T-1}{S-1} \\frac{S-T-1}{S-1} , and so on. This probability is approximately \\approx 1-(1-\\frac{T}{S})^m\\approx 1-e^{-mT/S} \\approx 1-(1-\\frac{T}{S})^m\\approx 1-e^{-mT/S} . Then the read cost can be calculated by r(\\vec k)=(\\sum_{T} 1-e^{-mT/S})(block\\ size) r(\\vec k)=(\\sum_{T} 1-e^{-mT/S})(block\\ size) . The write cost is the same as problem 2. The code of estimation is in Part3Benchmark function. Your task: given the size of the last level N N , the base level size F F , the workload parameter alpha alpha , and the range scan length m m , approximate the read cost and write cost, find \\vec k, C \\vec k, C that minimize f(\\vec k, C) = w(\\vec k, C) + \\alpha r(\\vec k) f(\\vec k, C) = w(\\vec k, C) + \\alpha r(\\vec k) and satisfy N = \\prod_{i=1}^{L-1} k_i C F N = \\prod_{i=1}^{L-1} k_i C F . You need to implement it in FluidCompactionPicker::Get . We provide a basic benchmark that can be executed by test/test_lsm --gtest_filter=LSMTest.Part3Benchmark2 . Your algorithm should outperform than the baseline. There is no need to submit to autolab due to the long execution time. Please write a report detailing the algorithm you have designed and implemented. Additionally, include a comprehensive comparison with other compaction policies. Compare your algorithm with other compaction policies, including leveling, tiering, and lazy leveling in problem 1. Furthermore, adjust the alpha value in the benchmark, and determine the range of alpha where your algorithm performs the best. The parameters in Part3Benchmark(alpha, N, scan_length) are: alpha value, N is the number of keys, scan_length is the length of range scan. scan_length is set to 100 by default. You can also pass different scan_length to this function. The read cost is calculated as follows: read cost = 0 write cost = 0 for T in range(10): insert 10% of key-value pairs read cost += (number of sorted runs that need to be accessed) * (block size) * (number of inserted key pairs) write cost += (write cost of inserted key pairs) read cost /= 10 write cost /= 10 total cost = (read cost) * alpha + (write cost) You can get points as long as your solution is reasonable and well-founded.","title":"Problem 3: find the best compaction policy considering range filters (3pts)"},{"location":"p2/overview/","text":"In Project 2, you will implement a pull-based vectorized execution engine. Vectorized engine Volcano-style engines are simple and easy to implement, but they have poor performance due to the large overhead in virtual function calls. While they worked well in the past because disk I/O was the primary bottleneck, they are inefficient on modern CPUs and disks. Most modern query engines either use vectorization or data-centric code generation (just-in-time compilation). Vectorized engines fetch a batch of tuples instead of just one at a time, which amortizes the virtual function call overhead and can leverage SIMD (Single Instruction, Multiple Data) techniques. In execution/executor.hpp , you can find the interfaces in VecExecutor . The interfaces are: Init() : Initializes the executor. Next() : Returns a batch of tuples. If there are no tuples to return, it returns an empty result. Operators (Executors) are organized as a tree. The system calls the Next() function of the root operator of the tree, then the root operator calls the Next() functions of its children, and so on. The leaf operators of the tree are SeqScanVecExecutor which read tuple data from the storage engine and allocate a buffer to store them in memory. The tuple data is processed and transferred from the leaf to the root, and return to the system. The system calls Next() until it returns empty result. Data structure The batch of tuples is stored in TupleBatch (refer to type/tuple_batch.hpp ). TupleBatch has Vector s storing each column (refer to type/vector.hpp and type/vector_buffer.hpp ) and a selection vector storing validation bits. The selection vector is used in cases of low selectivity (for example, when 95\\% of tuples are valid, we do not need to eliminate invalid ones; instead we just mark them as invalid.). Each Vector has an array of elements. Each element is of type StaticFieldRef (refer to type/static_field.hpp ). It is an 8-byte object that can store a 64-bit integer ( LogicalType::INT , refer to type/field_type.hpp ) or 64-bit float ( LogicalType::FLOAT ) or a string pointer ( LogicalType::STRING ). If the Vector stores strings, it stores an array of string pointers and a pointer to an auxlitary buffer ( Vector::aux_ ) which stores actual string data. The figure above shows the structure of TupleBatch . The types of tuple are: LogicalType::INT , LogicalType::FLOAT , LogicalType::INT , LogicalType::STRING . The Vector which stores column D has a pointer to an auxlitary buffer storing actual string data. In TupleBatch , num_tuple_ stores the number of tuples including valid ones and invalid ones, num_valid_tuple_ stores the number of valid tuples, capacity_ stores the maximum number of tuples. Like capacity and size in std::vector , capacity_ can be larger than num_tuple_ and tuples with indices between num_tuple_ and capacity_ - 1 are empty (neither valid nor invalid). To create a TupleBatch , you need to call TupleBatch::Init . You need to get the tuple type and pass it as std::vector<LogicalType> . If you have an OutputSchema , you can call OutputSchema::GetTypes() to get it. You also need to pass a initial size to the function, you can use max_batch_size_ (the maximum batch size) in VecExecutor , so that it will not need to resize during execution. Here is an example: OutputSchema table0_; TupleBatch batch; batch.Init(table0_.GetTypes(), max_batch_size_); After the TupleBatch is created, it is empty, you can use TupleBatch::Append to append tuples. Note that this function deepcopies tuple data, i.e. it copies the string data and creates a new string pointer. So you do not need to worry about the string pointers being invalid. Here is an example: TupleBatch result_; std::vector<StaticFieldRef> tuple; ... // Append the tuple in std::vector<StaticFieldRef> result_.Append(tuple); std::vector<Vector> v; ... // Append all tuples in std::vector<Vector> for (int i = 0; i < tuple_cnt; i++) { result_.Append(v, i); } To access the j-th column of the i-th tuple, you can use TupleBatch::Get(i, j) . It returns a StaticFieldRef object, you can use ReadInt , ReadFloat or ReadStringView based on its type (type is not stored in StaticFieldRef , it is stored in other places such as OutputSchema ). To assign a value to the j-th column of the i-th tuple, you can use TupleBatch::Set(i, j, value) . To get a reference to the i-th tuple, you can use TupleBatch::GetSingleTuple(i) , it returns a TupleBatch::SingleTuple , a read-only reference. You can use operator[] to access the j-th column in TupleBatch::SingleTuple , for example GetSingleTuple(i)[j] accesses the j-th column of the i-th tuple. To iterate over the valid tuples in TupleBatch , you can use: (1) iterate over all the tuples and use TupleBatch::IsValid to check if they are valid, or (2) use TupleBatch::iterator and for(auto :) , it only returns valid tuples. It returns TupleBatch::SingleTuple , a read-only reference. Here is an example: // 1. TupleBatch batch; for (uint64_t i = 0; i < batch.size(); i++) { if (batch.IsValid(i)) { // batch.Get(i, j) access the j-th column of i-th tuple. } } // 2. TupleBatch batch; for (auto t : batch) { // use t[i] to access the i-th column of the tuple // use batch2.Append(t) to append the tuple to another tuple batch. } Vector has two types: constant and flat. If its type is flat, then it stores a normal array. If its type is constant, then it is a vector in which all the elements are the same. Physically it only stores one element. It is used for constants in the expressions, or nested loop join executors. To create a vector, you need to pass the vector type ( VectorType::Flat or VectorType::Constant ), the element type ( LogicalType::FLOAT , LogicalType::STRING and LogicalType::INT ), and the number of elements of the vector. There is no validation information in Vector . It assumes that all the elements in Vector are valid and need to be calculated in expression evaluation. OutputSchema Since SQL is a statically-typed language, the types of the output of operators are known. They are stored in OutputSchema (refer to plan/output_schema.hpp ) in PlanNode::output_schema_ (refer to plan/plan.hpp ). You can use OutputSchema::GetTypes to get types in std::vector<LogicalType> . To get more information, you can use OutputSchema::operator[] or OutputSchema::GetCols to get the OutputColumnData structure, which stores table name, column name, type, etc. You may also need to concatenate two OutputSchema s (e.g in the join executor), you can use OutputSchema::Concat(left, right) . ExprVecExecutor In vectorized execuction engine, expressions are evaluated in batches, greatly reducing the interpretation overhead. For each expression, we construct an executor called ExprVecExecutor (refer to execution/vec/expr_vexecutor.hpp ). ExprVecExecutor s are organized as a tree, where the leaf nodes of the tree are input, the root node stores the result into the result Vector . The expression is evaluated from the bottom to the top, and inner nodes (nodes that are not leafs) may need to allocate a buffer to store temporary results. Here is an example shown in the figure below. You can find ExprVecExecutor in execution/vec/expr_vexecutor.hpp . To create an ExprVecExecutor , you need to pass a pointer to Expr , which stores expression information, and a OutputSchema , which stores type information. To evaluate the expression, you need to pass a std::span<Vector> ( std::span is similar to std::string_view , but it is used for std::vector or std::array objects) with the same types in the OutputSchema you passed during creation, and the number of tuples (including valid tuples and invalid tuples, i.e. the return value of TupleBatch::size ) in the input, and a reference to the result Vector . Here is an example (refer to execution/vec/project_vexecutor.hpp ): OutputSchema input_schema; // The OutputSchema of the child executor, it has the type of input tuples. std::unique_ptr<Expr> expr; // The expression information expr_ = ExprVecExecutor::Create(expr.get(), input_schema); //... TupleBatch input; Vector result; // input.GetCols() returns all the columns in input. expr_.Evaluate(input.GetCols(), input.size(), result); // Or use array of Vectors as input std::vector<Vector> input; size_t cnt = ...; expr_.Evaluate(input, cnt, result); Use shell If you want to execute your own SQLs, you can call ./wing <DB file name> under build directory. The syntax is similar to PostgreSQL. Create a table: Different from standard SQL, the columns only have 4 types: int64, float64, int32 and varchar. create table A(a int64, b float64, c varchar(20), d int32); create table A2(a int64 primary key, b float64); -- a is the primary key of A2 create table A3(a int64 auto_increment primary key , b float64); -- a is the primary key and it is an auto_increment value (you can always pass 0 to it while inserting and it is automatically set to 1, 2, 3, 4....) create table A4(a int64 foreign key references A(a), b float64); -- a is a foreign key referencing A(a). create table A5(a int64 primary key foreign key references A(a), b float64); -- a is a foreign key referencing A(a) and it is the primary key of A5. Drop a table: drop table A; Insert into a table: insert into A values (2, 3, 'dsf', 4), (6, 7, 'asd', 8); Delete from a table: delete from A where a = 2; Scan a table: select a, b * 2 from A; Join two tables: select * from A, B; Join two tables on some predicates: select * from A join B on A.a = B.a; select * from A, B where A.a = B.a; To show the plan, you can use explain command: explain select * from A, B; Here is a possible result: Project [Output: a%0=A.a%0%int, a%2=B.a%2%int] -> Join [Predicate: ] -> Seq Scan [Table: A] [Predicate: ] -> Seq Scan [Table: B] [Predicate: ] If you want to exit: exit","title":"Overview"},{"location":"p2/overview/#vectorized-engine","text":"Volcano-style engines are simple and easy to implement, but they have poor performance due to the large overhead in virtual function calls. While they worked well in the past because disk I/O was the primary bottleneck, they are inefficient on modern CPUs and disks. Most modern query engines either use vectorization or data-centric code generation (just-in-time compilation). Vectorized engines fetch a batch of tuples instead of just one at a time, which amortizes the virtual function call overhead and can leverage SIMD (Single Instruction, Multiple Data) techniques. In execution/executor.hpp , you can find the interfaces in VecExecutor . The interfaces are: Init() : Initializes the executor. Next() : Returns a batch of tuples. If there are no tuples to return, it returns an empty result. Operators (Executors) are organized as a tree. The system calls the Next() function of the root operator of the tree, then the root operator calls the Next() functions of its children, and so on. The leaf operators of the tree are SeqScanVecExecutor which read tuple data from the storage engine and allocate a buffer to store them in memory. The tuple data is processed and transferred from the leaf to the root, and return to the system. The system calls Next() until it returns empty result.","title":"Vectorized engine"},{"location":"p2/overview/#data-structure","text":"The batch of tuples is stored in TupleBatch (refer to type/tuple_batch.hpp ). TupleBatch has Vector s storing each column (refer to type/vector.hpp and type/vector_buffer.hpp ) and a selection vector storing validation bits. The selection vector is used in cases of low selectivity (for example, when 95\\% of tuples are valid, we do not need to eliminate invalid ones; instead we just mark them as invalid.). Each Vector has an array of elements. Each element is of type StaticFieldRef (refer to type/static_field.hpp ). It is an 8-byte object that can store a 64-bit integer ( LogicalType::INT , refer to type/field_type.hpp ) or 64-bit float ( LogicalType::FLOAT ) or a string pointer ( LogicalType::STRING ). If the Vector stores strings, it stores an array of string pointers and a pointer to an auxlitary buffer ( Vector::aux_ ) which stores actual string data. The figure above shows the structure of TupleBatch . The types of tuple are: LogicalType::INT , LogicalType::FLOAT , LogicalType::INT , LogicalType::STRING . The Vector which stores column D has a pointer to an auxlitary buffer storing actual string data. In TupleBatch , num_tuple_ stores the number of tuples including valid ones and invalid ones, num_valid_tuple_ stores the number of valid tuples, capacity_ stores the maximum number of tuples. Like capacity and size in std::vector , capacity_ can be larger than num_tuple_ and tuples with indices between num_tuple_ and capacity_ - 1 are empty (neither valid nor invalid). To create a TupleBatch , you need to call TupleBatch::Init . You need to get the tuple type and pass it as std::vector<LogicalType> . If you have an OutputSchema , you can call OutputSchema::GetTypes() to get it. You also need to pass a initial size to the function, you can use max_batch_size_ (the maximum batch size) in VecExecutor , so that it will not need to resize during execution. Here is an example: OutputSchema table0_; TupleBatch batch; batch.Init(table0_.GetTypes(), max_batch_size_); After the TupleBatch is created, it is empty, you can use TupleBatch::Append to append tuples. Note that this function deepcopies tuple data, i.e. it copies the string data and creates a new string pointer. So you do not need to worry about the string pointers being invalid. Here is an example: TupleBatch result_; std::vector<StaticFieldRef> tuple; ... // Append the tuple in std::vector<StaticFieldRef> result_.Append(tuple); std::vector<Vector> v; ... // Append all tuples in std::vector<Vector> for (int i = 0; i < tuple_cnt; i++) { result_.Append(v, i); } To access the j-th column of the i-th tuple, you can use TupleBatch::Get(i, j) . It returns a StaticFieldRef object, you can use ReadInt , ReadFloat or ReadStringView based on its type (type is not stored in StaticFieldRef , it is stored in other places such as OutputSchema ). To assign a value to the j-th column of the i-th tuple, you can use TupleBatch::Set(i, j, value) . To get a reference to the i-th tuple, you can use TupleBatch::GetSingleTuple(i) , it returns a TupleBatch::SingleTuple , a read-only reference. You can use operator[] to access the j-th column in TupleBatch::SingleTuple , for example GetSingleTuple(i)[j] accesses the j-th column of the i-th tuple. To iterate over the valid tuples in TupleBatch , you can use: (1) iterate over all the tuples and use TupleBatch::IsValid to check if they are valid, or (2) use TupleBatch::iterator and for(auto :) , it only returns valid tuples. It returns TupleBatch::SingleTuple , a read-only reference. Here is an example: // 1. TupleBatch batch; for (uint64_t i = 0; i < batch.size(); i++) { if (batch.IsValid(i)) { // batch.Get(i, j) access the j-th column of i-th tuple. } } // 2. TupleBatch batch; for (auto t : batch) { // use t[i] to access the i-th column of the tuple // use batch2.Append(t) to append the tuple to another tuple batch. } Vector has two types: constant and flat. If its type is flat, then it stores a normal array. If its type is constant, then it is a vector in which all the elements are the same. Physically it only stores one element. It is used for constants in the expressions, or nested loop join executors. To create a vector, you need to pass the vector type ( VectorType::Flat or VectorType::Constant ), the element type ( LogicalType::FLOAT , LogicalType::STRING and LogicalType::INT ), and the number of elements of the vector. There is no validation information in Vector . It assumes that all the elements in Vector are valid and need to be calculated in expression evaluation.","title":"Data structure"},{"location":"p2/overview/#outputschema","text":"Since SQL is a statically-typed language, the types of the output of operators are known. They are stored in OutputSchema (refer to plan/output_schema.hpp ) in PlanNode::output_schema_ (refer to plan/plan.hpp ). You can use OutputSchema::GetTypes to get types in std::vector<LogicalType> . To get more information, you can use OutputSchema::operator[] or OutputSchema::GetCols to get the OutputColumnData structure, which stores table name, column name, type, etc. You may also need to concatenate two OutputSchema s (e.g in the join executor), you can use OutputSchema::Concat(left, right) .","title":"OutputSchema"},{"location":"p2/overview/#exprvecexecutor","text":"In vectorized execuction engine, expressions are evaluated in batches, greatly reducing the interpretation overhead. For each expression, we construct an executor called ExprVecExecutor (refer to execution/vec/expr_vexecutor.hpp ). ExprVecExecutor s are organized as a tree, where the leaf nodes of the tree are input, the root node stores the result into the result Vector . The expression is evaluated from the bottom to the top, and inner nodes (nodes that are not leafs) may need to allocate a buffer to store temporary results. Here is an example shown in the figure below. You can find ExprVecExecutor in execution/vec/expr_vexecutor.hpp . To create an ExprVecExecutor , you need to pass a pointer to Expr , which stores expression information, and a OutputSchema , which stores type information. To evaluate the expression, you need to pass a std::span<Vector> ( std::span is similar to std::string_view , but it is used for std::vector or std::array objects) with the same types in the OutputSchema you passed during creation, and the number of tuples (including valid tuples and invalid tuples, i.e. the return value of TupleBatch::size ) in the input, and a reference to the result Vector . Here is an example (refer to execution/vec/project_vexecutor.hpp ): OutputSchema input_schema; // The OutputSchema of the child executor, it has the type of input tuples. std::unique_ptr<Expr> expr; // The expression information expr_ = ExprVecExecutor::Create(expr.get(), input_schema); //... TupleBatch input; Vector result; // input.GetCols() returns all the columns in input. expr_.Evaluate(input.GetCols(), input.size(), result); // Or use array of Vectors as input std::vector<Vector> input; size_t cnt = ...; expr_.Evaluate(input, cnt, result);","title":"ExprVecExecutor"},{"location":"p2/overview/#use-shell","text":"If you want to execute your own SQLs, you can call ./wing <DB file name> under build directory. The syntax is similar to PostgreSQL. Create a table: Different from standard SQL, the columns only have 4 types: int64, float64, int32 and varchar. create table A(a int64, b float64, c varchar(20), d int32); create table A2(a int64 primary key, b float64); -- a is the primary key of A2 create table A3(a int64 auto_increment primary key , b float64); -- a is the primary key and it is an auto_increment value (you can always pass 0 to it while inserting and it is automatically set to 1, 2, 3, 4....) create table A4(a int64 foreign key references A(a), b float64); -- a is a foreign key referencing A(a). create table A5(a int64 primary key foreign key references A(a), b float64); -- a is a foreign key referencing A(a) and it is the primary key of A5. Drop a table: drop table A; Insert into a table: insert into A values (2, 3, 'dsf', 4), (6, 7, 'asd', 8); Delete from a table: delete from A where a = 2; Scan a table: select a, b * 2 from A; Join two tables: select * from A, B; Join two tables on some predicates: select * from A join B on A.a = B.a; select * from A, B where A.a = B.a; To show the plan, you can use explain command: explain select * from A, B; Here is a possible result: Project [Output: a%0=A.a%0%int, a%2=B.a%2%int] -> Join [Predicate: ] -> Seq Scan [Table: A] [Predicate: ] -> Seq Scan [Table: B] [Predicate: ] If you want to exit: exit","title":"Use shell"},{"location":"p2/part1/","text":"Part 1 In part 1, you will implement JoinVecExecutor and HashJoinVecExecutor . To start, add two new files execution/vec/hashjoin_vexecutor.hpp and execution/vec/join_vexecutor.hpp . Make sure to include them in execution/executor.cpp . JoinPlanNode and HashJoinPlanNode In JoinPlanNode , the predicate_ member stores join predicates decomposed by AND (e.g., select * from A, B where a.id = b.id AND a.name = b.name AND (a.age < b.age or a.cost > b.cost); -> an array of size 3 {a.id = b.id, a.name = b.name, a.age < b.age or a.cost > b.cost} ), you can use PredicateVec::GenExpr to generate a std::unique_ptr<Expr> . The output_schema_ member (which is inherited from its parent class) stores the output schema, ch_ and ch2_ stores pointers to its two children. Its type_ is PlanType::Join . In HashJoinPlanNode , the predicate_ , output_schema_ , ch_ , ch2_ members are as the same as JoinPlanNode . However, it has two arrays of expressions that store the hash keys. Hash keys are expressions like A = B where A only contains attributes from one side and B only contains attributes from the other side. These keys are used to build a hash table for the join operation. For example, in select * from A, B where A.id = B.id , A.id and B.id are hash keys. ch_ is considered as the left table (build table), and ch2_ is considered as the right table (probe table). The left_hash_exprs array stores A.id and right_hash_exprs array stores B.id . Its type_ equals to PlanType::HashJoin . During the optimization stage, a JoinPlanNode can be converted to a HashJoinPlanNode when it has hash keys. In execution/executor.cpp You need to add code to generate JoinVecExecutor for JoinPlanNode and HashJoinVecExecutor for HashJoinPlanNode in InternalGenerateVec . Ensure that you pass necessary parameters from plan nodes to executors. For example, in ProjectPlanNode , project_plan->output_exprs_ and project_plan->ch_->output_schema_ are passed to ProjectVecExecutor . Since join executors have 2 child executors, you need to call InternalGenerateVec recursively to get the executor for ch_ and ch2_ . Implementing HashJoinVecExecutor and JoinVecExecutor Create two classes that inherit from VecExecutor . In the constructors, pass ExecOptions to VecExecutor , which you can get using db.GetOptions().exec_options . Then implement VecExecutor::InternalNext , which should return a TupleBatch each time it is called. It should return an empty result if and only if there is no result to return. In addition, the size of the returned TupleBatch cannot exceed the maximum batch size (refer to ExecOptions::max_batch_size in execution/execoptions.hpp , it is 1024 by default). For JoinVecExecutor , you need to implement nested loop join. For HashJoinVecExecutor , you need to implement hash join. You can review them in the lectures. You do not need to worry about the size of build table is larger than the memory, we assume that the memory is large enough. For JoinVecExecutor , you need to store all the tuples from the build table. You can just use an array of TupleBatch to store them, or you can utilize the dynamic size mechanism of TupleBatch . Each time you fetch a TupleBatch from the probe table and you can just calculate the join predicate for each tuple from the probe table and a batch of tuples from the build table, or you can calculate the join predicate for each tuple from the build table and a batch of tuples from the probe table. You do not need to worry about the efficiency when the build table size or the probe table size is small compared to the other. For example, if the build table has only 1 tuple but the probe table has 1000 tuples, if it calculate for each tuple from the probe table, it will evaluate the predicate for 1 tuple from the build table and 1 tuple from the probe table 1000 times. We assume that the build table and the probe table are large then there is no such problem. More specifically, suppose you are calculating the predicate for one tuple from the build table and a tuple batch from the probe table. You need to create a std::vector<Vector> , in which the elements are constant Vector s from the build table and the flat Vector s from the probe table. Then pass the std::vector<Vector> to the predicate evaluation executor. For example: // The input of the predicate std::vector<Vector> input; // Enumerate all the columns in the tuple from the build table // And create a constant vector for (/* ... */) { // The constant vector for one column auto cv = Vector(VectorType::Constant, /* type */, /* the size of tuple batch from the probe table */); cv.Set(0, /* the value in the tuple from the build table */); input.push_back(cv); } // Enumerate all the flat vectors in the tuple batch from the probe table // And append them to the input. for (/* ... */) { input.push_back(/* the flat vector */) } if (predicate_) { predicate_.Evaluate(input, /* the size of tuple batch from the probe table */, /* the result vector */); } For HashJoinVecExecutor , you need to read all the tuples from the build table, and build a hash table. You can just use std::unordered_map for this purpose. For the hash function, you can use utils::Hash and utils::Hash8 . utils::Hash can hash any data and utils::Hash8 can only hash a 8-byte integer. For float numbers, you can just use utils::Hash8 to hash the binary representation. Specifically, TupleBatch::Get returns a StaticFieldRef , you can use StaticFieldRef::ReadInt to read a 8-byte integer from the object, even if its type is float. For strings, you need to use StaticFieldRef::ReadStringView() to read the string view, and use utils::Hash . To hash more than 1 elements, you can pass the hash value as the seed parameter, for example: seed = 0x1234; hash = utils::Hash8(114514, seed); hash = utils::Hash8(1919810, hash); ... When you fetch tuples from the child executors, you need to call Next() function but not InternalNext() function. Some statistics are maintained in Next() function and they will be used in Part2, Part3. There are also correctness checks in Next() function. Do not try to avoid them. Test You can use test/test_exec --gtest_filter=ExecutorJoinTest.* to test your code.","title":"Part 1"},{"location":"p2/part1/#part-1","text":"In part 1, you will implement JoinVecExecutor and HashJoinVecExecutor . To start, add two new files execution/vec/hashjoin_vexecutor.hpp and execution/vec/join_vexecutor.hpp . Make sure to include them in execution/executor.cpp .","title":"Part 1"},{"location":"p2/part1/#joinplannode-and-hashjoinplannode","text":"In JoinPlanNode , the predicate_ member stores join predicates decomposed by AND (e.g., select * from A, B where a.id = b.id AND a.name = b.name AND (a.age < b.age or a.cost > b.cost); -> an array of size 3 {a.id = b.id, a.name = b.name, a.age < b.age or a.cost > b.cost} ), you can use PredicateVec::GenExpr to generate a std::unique_ptr<Expr> . The output_schema_ member (which is inherited from its parent class) stores the output schema, ch_ and ch2_ stores pointers to its two children. Its type_ is PlanType::Join . In HashJoinPlanNode , the predicate_ , output_schema_ , ch_ , ch2_ members are as the same as JoinPlanNode . However, it has two arrays of expressions that store the hash keys. Hash keys are expressions like A = B where A only contains attributes from one side and B only contains attributes from the other side. These keys are used to build a hash table for the join operation. For example, in select * from A, B where A.id = B.id , A.id and B.id are hash keys. ch_ is considered as the left table (build table), and ch2_ is considered as the right table (probe table). The left_hash_exprs array stores A.id and right_hash_exprs array stores B.id . Its type_ equals to PlanType::HashJoin . During the optimization stage, a JoinPlanNode can be converted to a HashJoinPlanNode when it has hash keys.","title":"JoinPlanNode and HashJoinPlanNode"},{"location":"p2/part1/#in-executionexecutorcpp","text":"You need to add code to generate JoinVecExecutor for JoinPlanNode and HashJoinVecExecutor for HashJoinPlanNode in InternalGenerateVec . Ensure that you pass necessary parameters from plan nodes to executors. For example, in ProjectPlanNode , project_plan->output_exprs_ and project_plan->ch_->output_schema_ are passed to ProjectVecExecutor . Since join executors have 2 child executors, you need to call InternalGenerateVec recursively to get the executor for ch_ and ch2_ .","title":"In execution/executor.cpp"},{"location":"p2/part1/#implementing-hashjoinvecexecutor-and-joinvecexecutor","text":"Create two classes that inherit from VecExecutor . In the constructors, pass ExecOptions to VecExecutor , which you can get using db.GetOptions().exec_options . Then implement VecExecutor::InternalNext , which should return a TupleBatch each time it is called. It should return an empty result if and only if there is no result to return. In addition, the size of the returned TupleBatch cannot exceed the maximum batch size (refer to ExecOptions::max_batch_size in execution/execoptions.hpp , it is 1024 by default). For JoinVecExecutor , you need to implement nested loop join. For HashJoinVecExecutor , you need to implement hash join. You can review them in the lectures. You do not need to worry about the size of build table is larger than the memory, we assume that the memory is large enough. For JoinVecExecutor , you need to store all the tuples from the build table. You can just use an array of TupleBatch to store them, or you can utilize the dynamic size mechanism of TupleBatch . Each time you fetch a TupleBatch from the probe table and you can just calculate the join predicate for each tuple from the probe table and a batch of tuples from the build table, or you can calculate the join predicate for each tuple from the build table and a batch of tuples from the probe table. You do not need to worry about the efficiency when the build table size or the probe table size is small compared to the other. For example, if the build table has only 1 tuple but the probe table has 1000 tuples, if it calculate for each tuple from the probe table, it will evaluate the predicate for 1 tuple from the build table and 1 tuple from the probe table 1000 times. We assume that the build table and the probe table are large then there is no such problem. More specifically, suppose you are calculating the predicate for one tuple from the build table and a tuple batch from the probe table. You need to create a std::vector<Vector> , in which the elements are constant Vector s from the build table and the flat Vector s from the probe table. Then pass the std::vector<Vector> to the predicate evaluation executor. For example: // The input of the predicate std::vector<Vector> input; // Enumerate all the columns in the tuple from the build table // And create a constant vector for (/* ... */) { // The constant vector for one column auto cv = Vector(VectorType::Constant, /* type */, /* the size of tuple batch from the probe table */); cv.Set(0, /* the value in the tuple from the build table */); input.push_back(cv); } // Enumerate all the flat vectors in the tuple batch from the probe table // And append them to the input. for (/* ... */) { input.push_back(/* the flat vector */) } if (predicate_) { predicate_.Evaluate(input, /* the size of tuple batch from the probe table */, /* the result vector */); } For HashJoinVecExecutor , you need to read all the tuples from the build table, and build a hash table. You can just use std::unordered_map for this purpose. For the hash function, you can use utils::Hash and utils::Hash8 . utils::Hash can hash any data and utils::Hash8 can only hash a 8-byte integer. For float numbers, you can just use utils::Hash8 to hash the binary representation. Specifically, TupleBatch::Get returns a StaticFieldRef , you can use StaticFieldRef::ReadInt to read a 8-byte integer from the object, even if its type is float. For strings, you need to use StaticFieldRef::ReadStringView() to read the string view, and use utils::Hash . To hash more than 1 elements, you can pass the hash value as the seed parameter, for example: seed = 0x1234; hash = utils::Hash8(114514, seed); hash = utils::Hash8(1919810, hash); ... When you fetch tuples from the child executors, you need to call Next() function but not InternalNext() function. Some statistics are maintained in Next() function and they will be used in Part2, Part3. There are also correctness checks in Next() function. Do not try to avoid them.","title":"Implementing HashJoinVecExecutor and JoinVecExecutor"},{"location":"p2/part1/#test","text":"You can use test/test_exec --gtest_filter=ExecutorJoinTest.* to test your code.","title":"Test"},{"location":"p2/part2/","text":"Part 2 In part 2, you will implement a bottom-up optimizer. You will implement the DP algorithm to calculate the optimal join order. Add statistics in your executor You need to add the following code in your join executor and hash join executor: virtual size_t GetTotalOutputSize() const override { return ch0_->GetTotalOutputSize() + ch1_->GetTotalOutputSize() + stat_output_size_; } DP algorithm We are only considering optimizing the query under the following conditions: (1) The root executor is a project executor, with no other project executor in the executor tree. (2) The descendants of the root are join/hash join executors, except for leaves. (3) The leaf executors are sequential scan executors. (4) The number of table is small. The SQL statements like this: select <columns> from <tables> where <predicates> . For example, select * from A, B, C where A.id = B.id and B.id = C.id; is such a query. select max(a) from A, B where A.id = B.id; is not, because it has an aggregate executor. select * from (select * from A), B; is not, because it has multiple project executors. The DP algorithm is: Let f(S) f(S) be the cost of joining tables in set S S . Then we have f(S)=\\min_{T\\in S, T\\neq \\emptyset, S} cost(T, S-T)+f(T)+f(S-T) f(S)=\\min_{T\\in S, T\\neq \\emptyset, S} cost(T, S-T)+f(T)+f(S-T) where cost(T, S-T) cost(T, S-T) is the cost of joining T T and S-T S-T . We assume that the number of tables is small and you can use bits to represent the existence of tables in S S . For example, if there are 5 tables A, B, C, D, E , then S = 10 S = 10 represents \\{B, D\\} \\{B, D\\} . You can use the following method to enumerate all subsets of S S so that the time complexity is O(3^n) O(3^n) , where n n is the number of tables: // T is the subset. for (int T = (S - 1) & S; T != 0; T = (T - 1) & S) { // ... } You need to implement it in the CostBasedOptimizer::Optimize function in plan/cost_based_optimizer.hpp . The DP algorithm is executed if and only if the condition is satisfied (the number of table is smaller than 20) and the option enable_cost_based is set to true. If it is not satisfied, then we simply apply ConvertToHashJoinRule on the naive plan. For two table sets S S and T T , you need to check if they can use hash join. You need to collect all the predicates in the plan tree and check if there is a predicate that can be used for hash keys. More specifially, first, you need to traverse the plan tree and collect the PredicateVec objects in join plan nodes. (Since filter plan node has been pushed down by PushDownFilterRule (refer to plan/rules/push_down_filter.hpp ) in LogicalOptimizer::Optimize (refer to plan/logical_optimizer.cpp ), you do not need to consider filter plan node.) Each element in PredicateVec is a binary condition expression, refer to plan/plan_expr.hpp . For each predicate element in PredicateVec , you can check if it can be used for hash keys by the table bitsets. The table bitset is a binary number representing the table set, in which the i i -th bit is 1 if and only if the i i -th table is in the table set. Suppose the table bitset of S S is bs bs and the table bitset of T T is bt bt , you can check as follows: PredicateElement a; L = bs; R = bt; // only equal condition can use it if (a.expr_->op_ == OpType::EQ) { if (!a.CheckRight(L) && !a.CheckLeft(R) && a.CheckRight(R) && a.CheckLeft(L)) { return true; } if (!a.CheckLeft(L) && !a.CheckRight(R) && a.CheckRight(L) && a.CheckLeft(R)) { return true; } } To get the table bitset of S S , you can enumerate all the tables in S S and bitwise-OR the table_bitset_ field in their sequential scan nodes. In sequential scan nodes the table_bitset_ field is an one-hot vector representing the table itself. You can also enumerate table sets from small to large, store the result of subsets, so that you can just perform one bitwise-OR operation to calculate the new table set using old table set results. After executing DP algorithm, you need to create a new plan. You need to create plan nodes based on your DP result. You can create a nested loop join plan node as follows: auto join_plan = std::make_unique<JoinPlanNode>(); join_plan->table_bitset_ = /* the table bitset of the tables in the subtree */ join_plan->ch_ = /* build table (left) */ join_plan->ch2_ = /* probe table (right) */ join_plan->output_schema_ = OutputSchema::Concat( join_plan->ch_->output_schema_, join_plan->ch2_->output_schema_); join_plan->predicate_ = /* predicate, can be empty */ You can create a hash join plan node as follows: (About how to generate left/right hash expressions, you can refer to plan/rules/convert_to_hash_join.hpp ). auto hashjoin_plan = std::make_unique<HashJoinPlanNode>(); hashjoin_plan->table_bitset_ = /* the table bitset of the tables in the subtree */ hashjoin_plan->ch_ = /* build table (left) */ hashjoin_plan->ch2_ = /* probe table (right) */ hashjoin_plan->output_schema_ = OutputSchema::Concat( hashjoin_plan->ch_->output_schema_, hashjoin_plan->ch2_->output_schema_); hashjoin_plan->predicate_ = /* predicate, can be empty */ hashjoin_plan->left_hash_exprs_ = /* hash key of build table (left) */ hashjoin_plan->right_hash_exprs_ = /* hash key of probe table (right) */ For the project plan node, you do not need to create a new one because it is at root. You need to point its child to a new join plan node. Do not forget to assign the DP result (i.e. f(\\text{all tables in query}) f(\\text{all tables in query}) ) to the cost_ field of the root plan node, it will be used in test. You do not need do anything for sequential scan node (predicate has been pushed down). Cost function You can find scan_cost and hash_join_cost in the OptimizerOptions . The cost of nested loop join is: \\text{scan cost} \\times (\\text{build table size}) \\times (\\text{probe table size}) \\text{scan cost} \\times (\\text{build table size}) \\times (\\text{probe table size}) The cost of hash join is: \\text{hash join cost} \\times ((\\text{build table size}) + (\\text{probe table size})) + \\text{scan cost}\\times (\\text{output size}) \\text{hash join cost} \\times ((\\text{build table size}) + (\\text{probe table size})) + \\text{scan cost}\\times (\\text{output size}) For example, suppose the output size is 3000, the cost of joining table A (1000 rows), B (2000 rows) is 3000(\\text{hash join cost})+3000(\\text{scan cost}) 3000(\\text{hash join cost})+3000(\\text{scan cost}) (hash join) or 2000000(\\text{scan cost}) 2000000(\\text{scan cost}) (nested loop join). We provide the true cardinality for all possible table sets. It is stored in true_cardinality_hints in the OptimizerOptions . The true_cardinality_hints is a std::optional variable, you can use true_cardinality_hints.has_value() to test if it is valid. If it is valid, it is a std::vector contains pairs storing table sets and the true cardinality of the table sets. The table sets are ordered by the number calculated by \\sum_{i\\in S} 2^i \\sum_{i\\in S} 2^i where S S is the table set, i\\in S i\\in S means the i i -th table in the table list is in S S . For example, for 3 tables A, B, C , the content in the vector is: {(), ({\"A\"}, ...), ({\"B\"}, ...), ({\"A\", \"B\"}, ...), ({\"C\"}, ...), ({\"A\", \"C\"}, ...), ({\"B\", \"C\"}, ...), ({\"A\", \"B\", \"C\"}, ...)} . You can reorder it if necessary. Test Use test/test_opm --gtest_filter=EasyOptimizerTest.Join5TablesCrossProduct:EasyOptimizerTest.Join3Tables to test you code. These tests are simple. More tests will be added later.","title":"Part 2"},{"location":"p2/part2/#part-2","text":"In part 2, you will implement a bottom-up optimizer. You will implement the DP algorithm to calculate the optimal join order.","title":"Part 2"},{"location":"p2/part2/#add-statistics-in-your-executor","text":"You need to add the following code in your join executor and hash join executor: virtual size_t GetTotalOutputSize() const override { return ch0_->GetTotalOutputSize() + ch1_->GetTotalOutputSize() + stat_output_size_; }","title":"Add statistics in your executor"},{"location":"p2/part2/#dp-algorithm","text":"We are only considering optimizing the query under the following conditions: (1) The root executor is a project executor, with no other project executor in the executor tree. (2) The descendants of the root are join/hash join executors, except for leaves. (3) The leaf executors are sequential scan executors. (4) The number of table is small. The SQL statements like this: select <columns> from <tables> where <predicates> . For example, select * from A, B, C where A.id = B.id and B.id = C.id; is such a query. select max(a) from A, B where A.id = B.id; is not, because it has an aggregate executor. select * from (select * from A), B; is not, because it has multiple project executors. The DP algorithm is: Let f(S) f(S) be the cost of joining tables in set S S . Then we have f(S)=\\min_{T\\in S, T\\neq \\emptyset, S} cost(T, S-T)+f(T)+f(S-T) f(S)=\\min_{T\\in S, T\\neq \\emptyset, S} cost(T, S-T)+f(T)+f(S-T) where cost(T, S-T) cost(T, S-T) is the cost of joining T T and S-T S-T . We assume that the number of tables is small and you can use bits to represent the existence of tables in S S . For example, if there are 5 tables A, B, C, D, E , then S = 10 S = 10 represents \\{B, D\\} \\{B, D\\} . You can use the following method to enumerate all subsets of S S so that the time complexity is O(3^n) O(3^n) , where n n is the number of tables: // T is the subset. for (int T = (S - 1) & S; T != 0; T = (T - 1) & S) { // ... } You need to implement it in the CostBasedOptimizer::Optimize function in plan/cost_based_optimizer.hpp . The DP algorithm is executed if and only if the condition is satisfied (the number of table is smaller than 20) and the option enable_cost_based is set to true. If it is not satisfied, then we simply apply ConvertToHashJoinRule on the naive plan. For two table sets S S and T T , you need to check if they can use hash join. You need to collect all the predicates in the plan tree and check if there is a predicate that can be used for hash keys. More specifially, first, you need to traverse the plan tree and collect the PredicateVec objects in join plan nodes. (Since filter plan node has been pushed down by PushDownFilterRule (refer to plan/rules/push_down_filter.hpp ) in LogicalOptimizer::Optimize (refer to plan/logical_optimizer.cpp ), you do not need to consider filter plan node.) Each element in PredicateVec is a binary condition expression, refer to plan/plan_expr.hpp . For each predicate element in PredicateVec , you can check if it can be used for hash keys by the table bitsets. The table bitset is a binary number representing the table set, in which the i i -th bit is 1 if and only if the i i -th table is in the table set. Suppose the table bitset of S S is bs bs and the table bitset of T T is bt bt , you can check as follows: PredicateElement a; L = bs; R = bt; // only equal condition can use it if (a.expr_->op_ == OpType::EQ) { if (!a.CheckRight(L) && !a.CheckLeft(R) && a.CheckRight(R) && a.CheckLeft(L)) { return true; } if (!a.CheckLeft(L) && !a.CheckRight(R) && a.CheckRight(L) && a.CheckLeft(R)) { return true; } } To get the table bitset of S S , you can enumerate all the tables in S S and bitwise-OR the table_bitset_ field in their sequential scan nodes. In sequential scan nodes the table_bitset_ field is an one-hot vector representing the table itself. You can also enumerate table sets from small to large, store the result of subsets, so that you can just perform one bitwise-OR operation to calculate the new table set using old table set results. After executing DP algorithm, you need to create a new plan. You need to create plan nodes based on your DP result. You can create a nested loop join plan node as follows: auto join_plan = std::make_unique<JoinPlanNode>(); join_plan->table_bitset_ = /* the table bitset of the tables in the subtree */ join_plan->ch_ = /* build table (left) */ join_plan->ch2_ = /* probe table (right) */ join_plan->output_schema_ = OutputSchema::Concat( join_plan->ch_->output_schema_, join_plan->ch2_->output_schema_); join_plan->predicate_ = /* predicate, can be empty */ You can create a hash join plan node as follows: (About how to generate left/right hash expressions, you can refer to plan/rules/convert_to_hash_join.hpp ). auto hashjoin_plan = std::make_unique<HashJoinPlanNode>(); hashjoin_plan->table_bitset_ = /* the table bitset of the tables in the subtree */ hashjoin_plan->ch_ = /* build table (left) */ hashjoin_plan->ch2_ = /* probe table (right) */ hashjoin_plan->output_schema_ = OutputSchema::Concat( hashjoin_plan->ch_->output_schema_, hashjoin_plan->ch2_->output_schema_); hashjoin_plan->predicate_ = /* predicate, can be empty */ hashjoin_plan->left_hash_exprs_ = /* hash key of build table (left) */ hashjoin_plan->right_hash_exprs_ = /* hash key of probe table (right) */ For the project plan node, you do not need to create a new one because it is at root. You need to point its child to a new join plan node. Do not forget to assign the DP result (i.e. f(\\text{all tables in query}) f(\\text{all tables in query}) ) to the cost_ field of the root plan node, it will be used in test. You do not need do anything for sequential scan node (predicate has been pushed down).","title":"DP algorithm"},{"location":"p2/part2/#cost-function","text":"You can find scan_cost and hash_join_cost in the OptimizerOptions . The cost of nested loop join is: \\text{scan cost} \\times (\\text{build table size}) \\times (\\text{probe table size}) \\text{scan cost} \\times (\\text{build table size}) \\times (\\text{probe table size}) The cost of hash join is: \\text{hash join cost} \\times ((\\text{build table size}) + (\\text{probe table size})) + \\text{scan cost}\\times (\\text{output size}) \\text{hash join cost} \\times ((\\text{build table size}) + (\\text{probe table size})) + \\text{scan cost}\\times (\\text{output size}) For example, suppose the output size is 3000, the cost of joining table A (1000 rows), B (2000 rows) is 3000(\\text{hash join cost})+3000(\\text{scan cost}) 3000(\\text{hash join cost})+3000(\\text{scan cost}) (hash join) or 2000000(\\text{scan cost}) 2000000(\\text{scan cost}) (nested loop join). We provide the true cardinality for all possible table sets. It is stored in true_cardinality_hints in the OptimizerOptions . The true_cardinality_hints is a std::optional variable, you can use true_cardinality_hints.has_value() to test if it is valid. If it is valid, it is a std::vector contains pairs storing table sets and the true cardinality of the table sets. The table sets are ordered by the number calculated by \\sum_{i\\in S} 2^i \\sum_{i\\in S} 2^i where S S is the table set, i\\in S i\\in S means the i i -th table in the table list is in S S . For example, for 3 tables A, B, C , the content in the vector is: {(), ({\"A\"}, ...), ({\"B\"}, ...), ({\"A\", \"B\"}, ...), ({\"C\"}, ...), ({\"A\", \"C\"}, ...), ({\"B\", \"C\"}, ...), ({\"A\", \"B\", \"C\"}, ...)} . You can reorder it if necessary.","title":"Cost function"},{"location":"p2/part2/#test","text":"Use test/test_opm --gtest_filter=EasyOptimizerTest.Join5TablesCrossProduct:EasyOptimizerTest.Join3Tables to test you code. These tests are simple. More tests will be added later.","title":"Test"},{"location":"p2/part3/","text":"","title":"Part 3"}]}